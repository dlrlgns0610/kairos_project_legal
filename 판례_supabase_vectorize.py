"""
precedents_full 3-way ë²¡í„° ì»¬ëŸ¼ ì¼ê´„ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
-------------------------------------------------
 * ëŒ€ìƒ ì»¬ëŸ¼ : bsisfacts, courtdcss, relatelaword (TEXT/JSON string)
 * ë²¡í„° ì»¬ëŸ¼ : bsisfacts_vector, courtdcss_vector, relatelaword_vector (vector(1536))
 * ì„ë² ë”©   : OpenAI text-embedding-3-small (1536-d)
 * ì‹¤í–‰ ë°©ë²• :
     $ python bulk_embed_precedents.py
"""

import os, json, time, sys
import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv
from supabase import create_client, Client
from openai import OpenAI
from tqdm import tqdm
from httpx import RemoteProtocolError

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
SUPABASE_URL         = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")
OPENAI_API_KEY       = os.getenv("OPENAI_API_KEY")
BATCH_SIZE           = 5               # Supabase fetch size
EMBED_MODEL          = "text-embedding-3-small"

supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
oai                = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def to_text(obj: Any, max_chars: int = 3000) -> str:
    """Json string â†’ list â†’ joined text (fallback) + ê¸¸ì´ ì œí•œ"""
    if obj is None:
        return "[EMPTY]"
    try:
        parsed = json.loads(obj)
        text = ""
        if isinstance(parsed, list):
            text = " ".join(map(str, parsed))
        elif isinstance(parsed, dict):
            text = json.dumps(parsed, ensure_ascii=False)
        else:
            text = str(parsed)
    except Exception:
        text = str(obj)

    if not text.strip():
        return "[EMPTY]"

    # ìµœëŒ€ ê¸¸ì´ ì œí•œ
    return text[:max_chars]

def embed_batch(texts: List[str]) -> List[List[float]]:
    """OpenAI ì„ë² ë”© ë°°ì¹˜ í˜¸ì¶œ"""
    # OpenAI 3-small: 8192 tokens, 1500r/m ì œí•œ. í•„ìš” ì‹œ time.sleep ë¡œ rate-limit ì¡°ì ˆ
    cleaned = [t if t.strip() else "[EMPTY]" for t in texts]
    resp = oai.embeddings.create(model=EMBED_MODEL, input=cleaned)
    return [d.embedding for d in resp.data]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_ids_without_vectors(limit=BATCH_SIZE) -> List[Dict]:
    """vector ì»¬ëŸ¼ì´ NULL ì¸ rowë§Œ ê°€ì ¸ì˜¤ê¸°"""
    sel = ("id,bsisfacts,courtdcss,relatelaword")
    return (
        supabase.table("precedents_full")
        .select(sel)
        .is_("bsisfacts_vector", "null")
        .limit(limit)
        .execute()
        .data
    )

def process_batch(rows: List[Dict]):
    if not rows:
        return 0
    # â¶ í…ìŠ¤íŠ¸ ë³€í™˜
    facts_txt  = [to_text(r["bsisfacts"], max_chars=3000)      for r in rows]
    issue_txt  = [to_text(r["courtdcss"], max_chars=3000)      for r in rows]
    law_txt    = [to_text(r["relatelaword"], max_chars=3000)   for r in rows]

    # â· ì„ë² ë”© (3*batch â†’ OpenAI í˜¸ì¶œ 3íšŒ)
    facts_vec  = embed_batch(facts_txt)
    issue_vec  = embed_batch(issue_txt)
    law_vec    = embed_batch(law_txt)

    # â¸ Supabase ì—…ë°ì´íŠ¸
    updates = []
    for idx, row in enumerate(rows):
        vec_rec = {
            "id":                   row["id"],
            "bsisfacts_vector":     facts_vec[idx],
            "courtdcss_vector":     issue_vec[idx],
            "relatelaword_vector":  law_vec[idx],
        }
        updates.append(vec_rec)

    #   upsert ê°€ ì—†ìœ¼ë¯€ë¡œ ë°˜ë³µ update
    for rec in tqdm(updates, desc="ğŸ“¤ Uploading to Supabase"):
        for attempt in range(3):  # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
            try:
                supabase.table("precedents_full").update(rec).eq("id", rec["id"]).execute()
                break
            except RemoteProtocolError as e:
                tqdm.write(f"âš ï¸ ì¬ì‹œë„ {attempt+1}íšŒ (ID: {rec['id']}) - {str(e)}")
                time.sleep(1)
    return len(rows)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    total_done = 0
    start_time = time.time()

    while True:
        rows = fetch_ids_without_vectors(limit=BATCH_SIZE)
        if not rows:
            break
        done = process_batch(rows)
        total_done += done

        elapsed = time.time() - start_time
        avg_time = elapsed / total_done if total_done else 0
        est_total = total_done + BATCH_SIZE  # rough estimate
        eta = datetime.timedelta(seconds=round(avg_time * est_total - elapsed))
        tqdm.write(f"ğŸ”„ Embedded {done} rows (acc: {total_done}) | ETA: {eta}")

    print(f"\nâœ… ì „ì²´ ì™„ë£Œ! ì´ {total_done}ê±´ ë²¡í„° ìƒì„± ë° ì €ì¥ë¨. â±ï¸ ì´ ì†Œìš” ì‹œê°„: {datetime.timedelta(seconds=round(time.time() - start_time))}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
        sys.exit(0)