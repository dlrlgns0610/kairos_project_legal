{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f7e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_SERVICE_KEY = os.getenv(\"SUPABASE_SERVICE_KEY\")\n",
    "\n",
    "#openai\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "#supabase\n",
    "from supabase import create_client, Client\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f29368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Fact Agent\n",
    "\n",
    "class basicFactResponse(BaseModel):\n",
    "    basic_facts: list[str]  # ì—¬ëŸ¬ ë¬¸ì¥ í˜•íƒœë¡œ ë°˜í™˜\n",
    "\n",
    "def extract_basic_facts(user_input: str) -> list[str]:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "**ì—­í• **\n",
    "ë„ˆëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ì‘ì„±í•œ ì‚¬ê±´ ì„¤ëª…ì„ ì½ê³ , ê·¸ë¡œë¶€í„° ë²•ë¥ ì  ë¶„ì„ì„ ìœ„í•œ **ê¸°ì´ˆì‚¬ì‹¤(basic facts)** ì„ í•­ëª©ë³„ë¡œ ì¶”ì¶œí•˜ëŠ” ì—­í• ì„ ë§¡ì€ ë³€í˜¸ì‚¬ì•¼.\n",
    "\n",
    "**ì§€ì¹¨**\n",
    "- ì‚¬ìš©ìì˜ ê¸´ ì„¤ëª…ì—ì„œ **ì‚¬ê±´ì˜ ë°œìƒ ê²½ìœ„, ê³„ì•½ ë‚´ìš©, ì¼ì, ì¥ì†Œ, ìŸì  ê´€ë ¨ ì‚¬ì‹¤**ë“¤ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì •ë¦¬í•´.\n",
    "- ê° ê¸°ì´ˆ ì‚¬ì‹¤ì€ ë¬¸ì¥ í•˜ë‚˜ë¡œ í‘œí˜„í•˜ê³ , **íŒë¡€ í˜•ì‹ì˜ í‘œí˜„ ìŠ¤íƒ€ì¼**ì„ ë”°ë¥¼ ê²ƒ.\n",
    "- ì‹œê°„ìˆœìœ¼ë¡œ ì„œìˆ í•˜ë˜, ë…¼ë¦¬ì  ë§¥ë½ì´ íë¦„ ìˆê²Œ ì´ì–´ì§€ë„ë¡ êµ¬ì„±í•  ê²ƒ.\n",
    "- ì˜ê²¬, ê°ì •, í•´ì„ì€ ì œê±°í•˜ê³  **ê°ê´€ì  ì‚¬ì‹¤**ë§Œ ê¸°ìˆ í•  ê²ƒ.\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ**\n",
    "1. ì›ê³ ëŠ” 2021ë…„ 3ì›” 1ì¼, í”¼ê³  ì†Œìœ ì˜ ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ ì†Œì¬ ì•„íŒŒíŠ¸ë¥¼ ì „ì„¸ë³´ì¦ê¸ˆ 1ì–µ ì›ì— ì„ì°¨í•˜ì˜€ë‹¤.  \n",
    "2. ê³„ì•½ê¸°ê°„ì€ 2ë…„ìœ¼ë¡œ 2023ë…„ 2ì›” 28ì¼ê¹Œì§€ë¡œ ì •í•´ì¡Œë‹¤.  \n",
    "3. ì›ê³ ëŠ” ê³„ì•½ ì¢…ë£Œì¼ì— ë§ì¶”ì–´ ì´ì‚¬ë¥¼ ì™„ë£Œí•˜ì˜€ê³ , ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ìš”ì²­í•˜ì˜€ë‹¤.  \n",
    "4. í”¼ê³ ëŠ” ìê¸ˆ ì‚¬ì •ì„ ì´ìœ ë¡œ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ê±°ì ˆí•˜ì˜€ë‹¤.  \n",
    "5. ì›ê³ ëŠ” ë³´ì¦ê¸ˆ ë°˜í™˜ ìš”ì²­ì„ ë‚´ìš©ì¦ëª…ìœ¼ë¡œ 2023ë…„ 3ì›” 5ì¼ì— í†µì§€í•˜ì˜€ë‹¤.\n",
    "\n",
    "**ë‹µë³€ì€ ìœ„ì™€ ê°™ì´ ë²ˆí˜¸ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤˜.**\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format=basicFactResponse,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed.basic_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485f9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ìŸì  ë¶„ì„ ì—ì´ì „íŠ¸\n",
    "\n",
    "class LegalIssueResponse(BaseModel):\n",
    "    legal_issue: str\n",
    "\n",
    "def generate_legal_issue(description):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            **ì—­í• **\n",
    "            ë„ˆëŠ” ë¯¼ì‚¬, í˜•ì‚¬, í–‰ì • ì‚¬ê±´ì—ì„œ ë°œìƒí•˜ëŠ” ë³µìˆ˜ì˜ ìŸì ì„ ë¶„ì„í•˜ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì•¼.  \n",
    "            ì•„ë˜ ##ì‚¬ê±´ ì„¤ëª…##ì„ ë³´ê³ , ê´€ë ¨ëœ **ëª¨ë“  ë²•ì  ìŸì **ì„ ë¹ ì§ì—†ì´, ëª…í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë„ì¶œí•´ì¤˜.\n",
    "\n",
    "            **ì§€ì¹¨**\n",
    "            - ë°˜ë“œì‹œ í•œ ì¤„ ìš”ì•½ì´ ì•„ë‹Œ, ë‹¤ì–‘í•œ ìŸì ë“¤ì„ í•­ëª©ë³„ë¡œ ë‚˜ì—´í•´ì¤˜.\n",
    "            - ê° ìŸì ì€ êµ¬ì²´ì ì¸ ë²•ë¥ ì  í‘œí˜„ì„ í¬í•¨í•˜ì—¬ ëª…í™•í•˜ê²Œ ì‘ì„±í•´.\n",
    "            - ìŸì ì€ ì‹¤ì œ ë¯¼ì‚¬ì†Œì†¡ì—ì„œ ë‹¤ë¤„ì§ˆ ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ, ì±…ì„, ê¶Œë¦¬, ì ˆì°¨, ì§€ì—°ì†í•´ê¸ˆ ë“±ë„ ë¹ ì§ì—†ì´ í¬í•¨í•´.\n",
    "            - ì¶œë ¥ì€ ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œ:\n",
    "            <1. ~ì— ê´€í•œ ìŸì >  \n",
    "            <2. ~ì— ê´€í•œ ìŸì >  \n",
    "            â€¦\n",
    "\n",
    "            **ë‹µë³€ ì˜ˆì‹œ**\n",
    "            ##ì‚¬ê±´ ì„¤ëª…##\n",
    "            ì„ëŒ€ì°¨ ê³„ì•½ì´ ì¢…ë£Œë˜ì—ˆìœ¼ë‚˜ ì§‘ì£¼ì¸ì´ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ì§€ ì•Šê³  ìˆìœ¼ë©°, ì„ì°¨ì¸ì€ ì´ì‚¬ë¹„ìš©ìœ¼ë¡œ ì¸í•´ ì€í–‰ ëŒ€ì¶œê¹Œì§€ ë°›ì€ ìƒíƒœì…ë‹ˆë‹¤. ì§‘ì£¼ì¸ì€ ë°˜í™˜ì¼ì •ë„ ì œì‹œí•˜ì§€ ì•Šê³  ìˆìœ¼ë©° ì—°ë½ë„ íšŒí”¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "            ##ë²•ì  ìŸì ##\n",
    "            1. ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ í›„ ì„ëŒ€ì¸ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ ë¶ˆì´í–‰ì— ëŒ€í•œ ì±…ì„  \n",
    "            2. ì„ì°¨ì¸ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ì²­êµ¬ê¶Œ í–‰ì‚¬ì™€ ì´ì— ë”°ë¥¸ ë²•ì  ì ˆì°¨ (ë‚´ìš©ì¦ëª…, ì†Œì†¡ ì œê¸° ë“±)  \n",
    "            3. ì„ëŒ€ì¸ì˜ ì—°ë½ íšŒí”¼ ë° ì§€ì—°ì— ë”°ë¥¸ ì±„ë¬´ë¶ˆì´í–‰ ì¸ì • ì—¬ë¶€  \n",
    "            4. ì§€ì—°ì†í•´ê¸ˆ ì²­êµ¬ì˜ ë²•ì  ê·¼ê±°ì™€ ì ìš© ë²”ìœ„  \n",
    "            5. ì„ì°¨ì¸ì˜ ëŒ€ì¶œ ë°œìƒì— ë”°ë¥¸ ì¶”ê°€ ì†í•´ì— ëŒ€í•œ ë°°ìƒ ê°€ëŠ¥ì„±  \n",
    "            6. ë°˜í™˜ë¶ˆì´í–‰ ì‹œ ê°•ì œì§‘í–‰ì„ ìœ„í•œ ë³´ì „ì²˜ë¶„(ê°€ì••ë¥˜ ë“±)ì˜ í•„ìš”ì„±  \n",
    "            7. ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì— ë”°ë¥¸ ì„ì°¨ì¸ ë³´í˜¸ ì¡°í•­ ì ìš© ì—¬ë¶€  \n",
    "            8. ì†Œë©¸ì‹œíš¨ ë° ë°˜í™˜ì²­êµ¬ ì‹œì˜ ì…ì¦ ì±…ì„ ë¬¸ì œ\n",
    "\n",
    "            ---------------------------\n",
    "            ë‹µë³€ì€ ìœ„ ì˜ˆì‹œì²˜ëŸ¼ ìˆ«ì ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": description\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format=LegalIssueResponse,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.parsed.legal_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6de413e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#íŒë¡€ ê²€ìƒ‰ìš© ì§ˆì˜ ìƒì„± ì—ì´ì „íŠ¸\n",
    "\n",
    "def generate_precedent_queries(\n",
    "    legal_issue: str,\n",
    "    basic_facts: list[str],\n",
    "    case_categories: list[str]\n",
    ") -> list[str]:\n",
    "    system_prompt = \"\"\"\n",
    "ë„ˆëŠ” ë³€í˜¸ì‚¬ì´ì ë¦¬ê±¸ ì—”ì§€ë‹ˆì–´ë¡œì„œ ì‚¬ìš©ìê°€ ì œê³µí•œ 'ë²•ì  ìŸì ', 'ê¸°ì´ˆ ì‚¬ì‹¤ë“¤', 'ì‚¬ê±´ ë¶„ì•¼(ë¯¼ì‚¬, í˜•ì‚¬, í–‰ì •)'ì„ ë¶„ì„í•˜ê³ ,\n",
    "ê·¸ì— ê¸°ë°˜í•´ íŒë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **ë‹¤ì–‘í•œ ë¬¸ì¥ í˜•íƒœì˜ íŒë¡€ ê²€ìƒ‰ ì§ˆì˜ë¬¸ë“¤ì„ ìƒì„±**í•˜ëŠ” ì—­í• ì´ì•¼.\n",
    "\n",
    "**ìƒì„± ì›ì¹™**\n",
    "- ê° ë¬¸ì¥ì€ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì§ˆì˜ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìì—°ì–´ ë¬¸ì¥ì´ì–´ì•¼ í•œë‹¤.\n",
    "- ë°˜ë“œì‹œ í˜„ì‹¤ì˜ ì‚¬ê±´ì„ ê²€ìƒ‰í•˜ë“¯, **ê²€ìƒ‰ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ í˜•íƒœ**ë¡œ ì“¸ ê²ƒ\n",
    "- ì§ˆì˜ë§ˆë‹¤ ê´€ì (í–‰ìœ„ì, ìŸì , ì²­êµ¬ ì·¨ì§€ ë“±)ì„ ë‹¬ë¦¬í•´ **ë‹¤ì–‘í•œ ê²€ìƒ‰ ê²½ë¡œ**ë¥¼ ì œì‹œí•  ê²ƒ\n",
    "- ì‚¬ê±´ì˜ ë¶„ì•¼(ë¯¼ì‚¬/í˜•ì‚¬/í–‰ì •)ë¥¼ ê³ ë ¤í•´ í•´ë‹¹ ë²• ë¶„ì•¼ íŠ¹ì„±ì— ë§ëŠ” í‚¤ì›Œë“œì™€ ë¬¸ë§¥ì„ ë°˜ì˜í•  ê²ƒ\n",
    "\n",
    "**ì¶œë ¥ ì˜ˆì‹œ**\n",
    "[\n",
    "  \"ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ê±°ì ˆí•˜ëŠ” ì„ëŒ€ì¸ì— ëŒ€í•œ ì„ì°¨ì¸ì˜ ë°˜í™˜ì²­êµ¬ ê´€ë ¨ íŒë¡€\",\n",
    "  \"ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ í›„ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ì§€ ì•Šì€ ê²½ìš°ì˜ ë¶„ìŸ ì‚¬ë¡€\",\n",
    "  \"ì„ëŒ€ì°¨ ê³„ì•½ ë§Œë£Œ í›„ ì§‘ì£¼ì¸ì˜ ë°˜í™˜ ì§€ì—°ì— ëŒ€í•œ ì†í•´ë°°ìƒ ê´€ë ¨ íŒë¡€\"\n",
    "]\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹**\n",
    "- ê° ë¬¸ì¥ ëì€ '~ íŒë¡€'ë¡œ ë§ˆë¬´ë¦¬\n",
    "\"\"\"\n",
    "\n",
    "    facts_summary = \"\\n\".join(f\"- {fact}\" for fact in basic_facts[:10])\n",
    "    category_summary = \", \".join(case_categories)\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "## ì‚¬ê±´ ë¶„ì•¼ ##\n",
    "{category_summary}\n",
    "\n",
    "## ë²•ì  ìŸì  ##\n",
    "{legal_issue}\n",
    "\n",
    "## ê¸°ì´ˆ ì‚¬ì‹¤ ##\n",
    "{facts_summary}\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content.strip())\n",
    "    except:\n",
    "        return [\n",
    "            line.strip(\"-â€¢ \").strip()\n",
    "            for line in response.choices[0].message.content.strip().splitlines()\n",
    "            if line.strip()\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da706ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ê±´ ë¶„ì•¼ ë¶„ë¥˜ ì—ì´ì „íŠ¸\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "\n",
    "# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYê°€ ìˆì–´ì•¼ í•¨)\n",
    "import os\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# âœ… Pydantic ëª¨ë¸ ì •ì˜\n",
    "class CaseDomainResponse(BaseModel):\n",
    "    domains: List[str]\n",
    "\n",
    "# âœ… ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜\n",
    "def classify_legal_domains(client_input: str) -> List[str]:\n",
    "    system_prompt = \"\"\"\n",
    "**ì—­í• **\n",
    "ë„ˆëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ì„œìˆ í•œ ì‚¬ê±´ ì„¤ëª…ì„ ì½ê³ , ì´ ì‚¬ê±´ì´ ì–´ëŠ ë²•ë¥  ì˜ì—­(ë¯¼ì‚¬, í˜•ì‚¬, í–‰ì •)ì— í•´ë‹¹í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì•¼.\n",
    "\n",
    "**íŒë‹¨ ê¸°ì¤€**\n",
    "- ë¯¼ì‚¬: ê°œì¸ ê°„ì˜ ì¬ì‚°, ê³„ì•½, ì†í•´ë°°ìƒ, ì„ëŒ€ì°¨, ë¶€ë‹¹ì´ë“, ë¶ˆë²•í–‰ìœ„ ë“±\n",
    "- í˜•ì‚¬: ë²”ì£„ í–‰ìœ„ (ì ˆë„, í­í–‰, ì‚¬ê¸° ë“±)ì— ë”°ë¥¸ í˜•ì‚¬ì²˜ë²Œ ë˜ëŠ” í˜•ì‚¬ì†Œì†¡\n",
    "- í–‰ì •: ê³µë¬´ì› ì§•ê³„, í—ˆê°€ì·¨ì†Œ, ì„¸ê¸ˆ, í–‰ì •ì²­ì˜ ì²˜ë¶„ì— ëŒ€í•œ ë¶ˆë³µ ë“± í–‰ì •ê¸°ê´€ ìƒëŒ€ ì‚¬ê±´\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹**\n",
    "[\"ë¯¼ì‚¬\"], [\"í˜•ì‚¬\"], [\"ë¯¼ì‚¬\", \"í˜•ì‚¬\"]ì²˜ëŸ¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ íŒë‹¨ ê²°ê³¼ë¥¼ ì œê³µí•´ì¤˜. ì ˆëŒ€ ë‹¤ë¥¸ ë‹¨ì–´ë‚˜ ì„¤ëª… ì—†ì´!\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "- â€œíšŒì‚¬ì—ì„œ í•´ê³ ë‹¹í–ˆëŠ”ë° ë¶€ë‹¹í•´ê³ ë¼ê³  ìƒê°í•´ìš”.â€ â†’ [â€œë¯¼ì‚¬â€]\n",
    "- â€œë„ë¡œêµí†µë²• ìœ„ë°˜ìœ¼ë¡œ ë²Œê¸ˆí˜•ì„ ë°›ì•˜ëŠ”ë° ì–µìš¸í•´ìš”.â€ â†’ [â€œí˜•ì‚¬â€]\n",
    "- â€œê³µë¬´ì›ì¸ë° ì •ì§ ì²˜ë¶„ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.â€ â†’ [â€œí–‰ì •â€]\n",
    "- â€œìƒí•´ì£„ë¡œ ê³ ì†Œë„ ë‹¹í–ˆì§€ë§Œ, ìƒëŒ€ë°©ì—ê²Œ ì¹˜ë£Œë¹„ ì²­êµ¬ë„ í•˜ê³  ì‹¶ì–´ìš”.â€ â†’ [â€œí˜•ì‚¬â€, â€œë¯¼ì‚¬â€]\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": client_input}\n",
    "    ]\n",
    "\n",
    "    # âœ… êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹±\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        response_format=CaseDomainResponse\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed.domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc7abc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê´€ë ¨ ì¡°ë¬¸ ì¶”ì²œ ì—ì´ì „íŠ¸\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "class RelevantLawListResponse(BaseModel):\n",
    "    relevant_laws: List[str]\n",
    "\n",
    "def recommend_relevant_laws(\n",
    "    legal_issue: str,\n",
    "    facts: List[str],\n",
    "    case_categories: List[str]\n",
    ") -> List[str]:\n",
    "    system_prompt = \"\"\"\n",
    "**ì—­í• **\n",
    "ë„ˆëŠ” ë²•ë¥  ì „ë¬¸ê°€ë¡œì„œ, ì‚¬ìš©ìê°€ ì œê³µí•œ 'ë²•ì  ìŸì ', 'ê¸°ì´ˆ ì‚¬ì‹¤ë“¤', 'ì‚¬ê±´ ë¶„ì•¼'ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ **ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë²•ë ¹ ì¡°í•­**ì„ **ê°€ëŠ¥í•œ í•œ ë§ì´** ì¶”ì²œí•˜ëŠ” ì—­í• ì„ ë§¡ì•˜ì–´.\n",
    "\n",
    "**ì§€ì¹¨**\n",
    "- ë°˜ë“œì‹œ í•´ë‹¹ ì‚¬ê±´ì˜ ìŸì ê³¼ ì‚¬ì‹¤ì— ê´€ë ¨ëœ ì¡°ë¬¸ë§Œ ì¶”ì²œí•  ê²ƒ.\n",
    "- ê° ì¡°ë¬¸ì€ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±:\n",
    "  \"<ë²•ë ¹ëª…> ì œXì¡° (ì¡°ë¬¸ ì œëª©)\"\n",
    "- í•œ ì¡°ë¬¸ë‹¹ í•œ ì¤„ì”© ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±í•˜ê³ , ê´€ë ¨ì´ ë‚®ê±°ë‚˜ ìœ ì‚¬ ì¡°í•­ì€ ì œì™¸í•  ê²ƒ.\n",
    "- ìµœëŒ€í•œ ë‹¤ì–‘í•œ ë²•ë ¹(ë¯¼ë²•, í˜•ë²•, ì•½ê´€ë²• ë“± í¬í•¨)ì„ ë°˜ì˜í•´ë„ ì¢‹ì§€ë§Œ, ìŸì ê³¼ì˜ ê´€ë ¨ì„±ì´ ê°€ì¥ ì¤‘ìš”í•¨.\n",
    "\n",
    "**ì˜ˆì‹œ ì¶œë ¥**\n",
    "[\n",
    "  \"ë¯¼ë²• ì œ618ì¡° (ì„ëŒ€ì°¨ì˜ ì •ì˜)\",\n",
    "  \"ë¯¼ë²• ì œ623ì¡° (ì„ëŒ€ì¸ì˜ ì˜ë¬´)\",\n",
    "  \"ë¯¼ë²• ì œ750ì¡° (ë¶ˆë²•í–‰ìœ„)\",\n",
    "  \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° (ëŒ€í•­ë ¥ ë“±)\",\n",
    "  \"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ4ì¡° (ê³„ì•½ê°±ì‹ ê³¼ ë³´ì¦ê¸ˆ ë°˜í™˜)\"\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "    facts_summary = \"\\n\".join(f\"- {fact}\" for fact in facts[:10])\n",
    "    domain_text = \", \".join(case_categories)\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "## ì‚¬ê±´ ë¶„ì•¼ ##\n",
    "{domain_text}\n",
    "\n",
    "## ë²•ì  ìŸì  ##\n",
    "{legal_issue}\n",
    "\n",
    "## ê¸°ì´ˆ ì‚¬ì‹¤ ##\n",
    "{facts_summary}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format=RelevantLawListResponse,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed.relevant_laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e23d3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #íŒë¡€ ê²€ìƒ‰ ì—ì´ì „íŠ¸\n",
    "\n",
    "# # search_similar_precedents_from_supabase.py\n",
    "# import os\n",
    "# from typing import List, Tuple, Set, Dict\n",
    "# from collections import Counter\n",
    "# from dotenv import load_dotenv\n",
    "# from supabase import create_client, Client\n",
    "# from openai import OpenAI\n",
    "\n",
    "# load_dotenv()\n",
    "# supabase: Client = create_client(os.getenv(\"SUPABASE_URL\"),\n",
    "#                                  os.getenv(\"SUPABASE_SERVICE_KEY\"))\n",
    "# client           = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "# def search_similar_precedents_from_supabase(\n",
    "#     precedent_queries: List[str],\n",
    "#     legal_issue: str,\n",
    "#     basic_facts: List[str],\n",
    "#     legal_domains: List[str] | None = None,\n",
    "# ) -> Tuple[str, List[Dict]]:\n",
    "#     \"\"\"RPC í•¨ìˆ˜ë¥¼ ì´ìš©í•´ íŒë¡€ ê²€ìƒ‰ â†’ ìš”ì•½\"\"\"\n",
    "#     matched: List[Dict] = []\n",
    "\n",
    "#     for keyword in precedent_queries:\n",
    "#         q = keyword.strip()\n",
    "#         if not q:\n",
    "#             continue\n",
    "\n",
    "#         for dom in (legal_domains or [None]):   # None â†’ casetype ì „ì²´\n",
    "#             try:\n",
    "#                 resp = supabase.rpc(\n",
    "#                     \"rpc_search_precedents\",\n",
    "#                     {\"q\": q, \"p_domain\": dom, \"p_limit\": 15},\n",
    "#                 ).execute()\n",
    "#                 matched.extend(resp.data)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"â— Supabase RPC ì˜¤ë¥˜: {q} / {e}\")\n",
    "\n",
    "#     # â”€â”€ ì¤‘ë³µ ì œê±° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     seen: Set[str] = set()\n",
    "#     unique_cases: List[Dict] = []\n",
    "#     for case in matched:\n",
    "#         if case[\"caseno\"] not in seen:\n",
    "#             seen.add(case[\"caseno\"])\n",
    "#             unique_cases.append(case)\n",
    "\n",
    "#     if not unique_cases:\n",
    "#         return (\"ğŸ” ìœ ì‚¬ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\", [])\n",
    "\n",
    "#     # â”€â”€ ìš”ì•½ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     prompt = f\"\"\"\n",
    "# ë‹¤ìŒ ì‚¬ê±´ì˜ ìŸì Â·ê¸°ì´ˆ ì‚¬ì‹¤ ë° ìœ ì‚¬ íŒë¡€ ëª©ë¡ì´ì•¼.\n",
    "# ìœ ì‚¬ì Â·ì°¨ì´ì , íŒê²° ê²½í–¥ì„ 6ì¤„ ë‚´ë¡œ ìš”ì•½í•´ì¤˜.\n",
    "\n",
    "# ## ìŸì \n",
    "# {legal_issue}\n",
    "\n",
    "# ## ì‚¬ì‹¤\n",
    "# {chr(10).join('- ' + f for f in basic_facts)}\n",
    "\n",
    "# ## íŒë¡€\n",
    "# {chr(10).join('- ' + c['caseno'] + ' / ' + (c.get('casenm') or '') for c in unique_cases)}\n",
    "# \"\"\".strip()\n",
    "\n",
    "#     completion = client.chat.completions.create(\n",
    "#         model=\"gpt-4o\",\n",
    "#         temperature=0.3,\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"ë„ˆëŠ” í•œêµ­ íŒë¡€ ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#         ],\n",
    "#     )\n",
    "#     return completion.choices[0].message.content.strip(), unique_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28fe2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Supabase ê¸°ë°˜ íŒë¡€ ê²€ìƒ‰ ì—ì´ì „íŠ¸ (vector-based re-ranking)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"\"\"\n",
    "Prerequisite\n",
    "------------\n",
    "1. Supabase Postgresì— pgvector í™•ì¥ ì„¤ì¹˜\n",
    "   CREATE EXTENSION IF NOT EXISTS vector;\n",
    "2. precedents_full í…Œì´ë¸”ì— ë‹¤ìŒ ë²¡í„° ì»¬ëŸ¼ ì¡´ì¬\n",
    "   - bsisfacts_vector    vector(768)\n",
    "   - courtdcss_vector    vector(768)\n",
    "   - relatelaword_vector vector(768)\n",
    "3. Python íŒ¨í‚¤ì§€: openai, supabase-py, numpy, python-dotenv\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, json, numpy as np\n",
    "from typing import List, Tuple\n",
    "from functools import lru_cache\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "from openai import OpenAI\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "load_dotenv()\n",
    "SUPABASE_URL         = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_SERVICE_KEY = os.getenv(\"SUPABASE_SERVICE_KEY\")\n",
    "OPENAI_API_KEY       = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)\n",
    "oai              = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ util: any â†’ str â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _to_text(x) -> str:\n",
    "    \"\"\"\n",
    "    embed() ì— ì•ˆì „í•˜ê²Œ ë„˜ê¸¸ ìˆ˜ ìˆë„ë¡ íƒ€ì…ì„ ë¬¸ìì—´ë¡œ ì •ê·œí™”\n",
    "    â€¢ list/tuple  â†’ ì¤„ë°”ê¿ˆ join\n",
    "    â€¢ dict       â†’ pretty JSON\n",
    "    â€¢ None       â†’ \"\"\n",
    "    â€¢ ê¸°íƒ€       â†’ str(x)\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return \"\\n\".join(map(str, x))\n",
    "    if isinstance(x, dict):\n",
    "        return json.dumps(x, ensure_ascii=False, indent=2)\n",
    "    return str(x)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ util: ì„ë² ë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@lru_cache(maxsize=1024)\n",
    "def embed(text: str, model: str = \"text-embedding-3-small\") -> List[float]:\n",
    "    \"\"\"OpenAI ì„ë² ë”© í˜¸ì¶œ ê²°ê³¼ë¥¼ LRU ìºì‹œ\"\"\"\n",
    "    resp = oai.embeddings.create(model=model, input=text)\n",
    "    return resp.data[0].embedding    # 1536-D (3-small ê¸°ì¤€)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def search_similar_precedents_from_supabase(\n",
    "    *,                               # keyword-only\n",
    "    basic_facts:  str | list | dict | None = None,\n",
    "    legal_issue:  str | list | dict | None = None,\n",
    "    related_laws: str | list | dict | None = None,\n",
    "    # LangGraph alias\n",
    "    precedent_queries: str | list | None = None,\n",
    "    legal_domains:     str | None = None,\n",
    "    case_type:         str | None = None,\n",
    "    # search params\n",
    "    top_k:   int   = 10,\n",
    "    w_facts: float = 0.4,\n",
    "    w_issue: float = 0.4,\n",
    "    w_law:   float = 0.2,\n",
    ") -> Tuple[str, List[dict]]:\n",
    "    \"\"\"pgvector + GPT-4o ìš”ì•½ ê¸°ë°˜ ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰\"\"\"\n",
    "\n",
    "    # 0ï¸âƒ£ alias ë§¤í•‘ -------------------------------------------------\n",
    "    if case_type is None and legal_domains is not None:\n",
    "        case_type = legal_domains\n",
    "    case_type = case_type or \"civil\"          # ê¸°ë³¸ê°’\n",
    "\n",
    "    # ğŸ‘‰ ë¦¬ìŠ¤íŠ¸Â·íŠœí”Œì´ë©´ ì²« ë²ˆì§¸ ì›ì†Œ(ë˜ëŠ” join)ë§Œ ì‚¬ìš©\n",
    "    if isinstance(case_type, (list, tuple)):\n",
    "        case_type = case_type[0] if case_type else \"civil\"\n",
    "    case_type = str(case_type)                # ë°©ì–´ì  ìºìŠ¤íŒ…\n",
    "\n",
    "    # ğŸ†• ì˜ë¬¸ â†’ êµ­ë¬¸ ë§¤í•‘\n",
    "    CASE_TYPE_MAP = {\n",
    "        \"civil\"   : \"ë¯¼ì‚¬\",\n",
    "        \"criminal\": \"í˜•ì‚¬\",\n",
    "        \"admin\"   : \"í–‰ì •\",\n",
    "    }\n",
    "    case_type = CASE_TYPE_MAP.get(case_type, case_type)   # ë³€í™˜\n",
    "\n",
    "    if basic_facts is None and precedent_queries is not None:\n",
    "        basic_facts = precedent_queries        # ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ\n",
    "\n",
    "    # 1ï¸âƒ£ ë¬¸ìì—´ ì •ê·œí™” ---------------------------------------------\n",
    "    basic_facts  = _to_text(basic_facts)\n",
    "    legal_issue  = _to_text(legal_issue)\n",
    "    related_laws = _to_text(related_laws)\n",
    "\n",
    "    # 2ï¸âƒ£ ì„ë² ë”© ------------------------------------------------------\n",
    "    fact_vec  = embed(basic_facts)\n",
    "    issue_vec = embed(legal_issue)\n",
    "    law_vec   = embed(related_laws)\n",
    "\n",
    "    # 3ï¸âƒ£ Supabase RPC í˜¸ì¶œ -----------------------------------------\n",
    "    payload = {\n",
    "        \"case_type\": case_type,\n",
    "        \"fact_vec\":  fact_vec,\n",
    "        \"issue_vec\": issue_vec,\n",
    "        \"law_vec\":   law_vec,\n",
    "        \"w_f\":       w_facts,\n",
    "        \"w_i\":       w_issue,\n",
    "        \"w_l\":       w_law,\n",
    "        \"k\":         top_k,\n",
    "    }\n",
    "    res = supabase.rpc(\"top_k_precedents\", payload).execute()\n",
    "    matches: List[dict] = res.data or []\n",
    "    if not matches:\n",
    "        return \"ğŸ” ìœ ì‚¬í•œ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\", []\n",
    "\n",
    "    # 4ï¸âƒ£ GPT-4o íŒë¡€ ìš”ì•½ ------------------------------------------\n",
    "    cases_list = \"\\n\".join(\n",
    "        f\"- ì‚¬ê±´ë²ˆí˜¸: {c['caseno']} / ì‚¬ê±´ëª…: {c.get('casenm','')}\"\n",
    "        for c in matches\n",
    "    )\n",
    "    summary_prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ íŒë¡€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì‚¬ê±´ì˜ ì‚¬ì‹¤ê´€ê³„Â·ìŸì ì— ìœ ì‚¬í•œ íŒë¡€ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "## ê¸°ì´ˆ ì‚¬ì‹¤\n",
    "{basic_facts}\n",
    "\n",
    "## ë²•ì  ìŸì \n",
    "{legal_issue}\n",
    "\n",
    "## ê´€ë ¨ ì¡°ë¬¸\n",
    "{related_laws}\n",
    "\n",
    "## ìœ ì‚¬ íŒë¡€ ëª©ë¡\n",
    "{cases_list}\n",
    "\"\"\"\n",
    "    chat = oai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.3,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë²•ë¥  íŒë¡€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "            {\"role\": \"user\",    \"content\": summary_prompt.strip()},\n",
    "        ],\n",
    "    )\n",
    "    summary_text = chat.choices[0].message.content.strip()\n",
    "    return summary_text, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc4a0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ë²•ì› íŒë‹¨ ì‹œë®¬ë ˆì´ì…˜ ì—ì´ì „íŠ¸\n",
    "\n",
    "class LegalJudgmentResponse(BaseModel):\n",
    "    judgment_summary: str\n",
    "\n",
    "def simulate_judgment(facts, precedents_summary, law_articles, case_type):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "**ì—­í• **\n",
    "ë„ˆëŠ” ì‹¤ì œ ë²•ì› íŒê²°ë¬¸ì„ ì‘ì„±í•˜ëŠ” íŒì‚¬ì•¼. ì‚¬ê±´ì˜ ì‚¬ì‹¤ê´€ê³„, ë²•ì  ìŸì , ì‚¬ê±´ ë¶„ì•¼, ì ìš© ë²•ë ¹, ê·¸ë¦¬ê³  ìœ ì‚¬ íŒë¡€ë“¤ì„ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ìµœì¢…ì ì¸ ë²•ì›ì˜ íŒë‹¨ì„ ë‚´ë¦¬ëŠ” ì—­í• ì´ì•¼.\n",
    "\n",
    "**ëª©í‘œ**\n",
    "ì£¼ì–´ì§„ ì •ë³´ë§Œìœ¼ë¡œ ë¯¼ì‚¬/í˜•ì‚¬/í–‰ì • ì‚¬ê±´ì— ëŒ€í•´ íŒê²°ë¬¸ ì¤‘ 'íŒë‹¨ ì´ìœ ' ë¶€ë¶„ì„ ì‘ì„±í•˜ë“¯, ë²•ì›ì´ ë‚´ë¦´ ë²•ì  íŒë‹¨ì„ êµ¬ì²´ì ì´ê³  ì²´ê³„ì ì´ë©° ë§¤ìš° ì „ë¬¸ì ì¸ ë…¼ì¦ìœ¼ë¡œ ì •ë¦¬í•´.\n",
    "\n",
    "**ì¶œë ¥ ê¸°ì¤€**\n",
    "- ë‹¨ í•˜ë‚˜ì˜ ê²°ë¡ ì´ ì•„ë‹ˆë¼, ë…¼ì¦ ì „ê°œë¥¼ í¬í•¨í•´ ì‹¤ì œ íŒê²°ë¬¸ì²˜ëŸ¼ ê¸¸ê³  ê¹Šì´ ìˆê²Œ ì‘ì„±í•´\n",
    "- ë²•ì  ìŸì ë³„ë¡œ íŒë‹¨ ê·¼ê±°ë¥¼ êµ¬ì¡°ì ìœ¼ë¡œ ì œì‹œí•´\n",
    "- ìœ ì‚¬ íŒë¡€ì™€ ë²• ì¡°í•­ì˜ ê·¼ê±°ë¥¼ ê²°í•©í•´ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , ì™œ í•´ë‹¹ ì‚¬ê±´ì—ë„ ë™ì¼í•˜ê²Œ íŒë‹¨í•´ì•¼ í•˜ëŠ”ì§€ ë°í˜€ì¤˜\n",
    "- íŒë¡€ì™€ì˜ ìœ ì‚¬ì„±ê³¼ ì°¨ì´ì , ë²• ì¡°í•­ì˜ í•´ì„ ì ìš© ê³¼ì •ë„ ìì„¸íˆ ì„¤ëª…í•´\n",
    "- ëë¶€ë¶„ì— ê²°ë¡ ì„ ëª…ì‹œí•˜ë˜, ë‹¨ìˆœíˆ \"ì±…ì„ì´ ì¸ì •ëœë‹¤\" ìˆ˜ì¤€ì´ ì•„ë‹ˆë¼ ì™œ ê·¸ë ‡ê²Œ íŒë‹¨í•˜ëŠ”ì§€ë¥¼ ì •ë¦¬í•´\n",
    "- ë¬¸ì¥ í•˜ë‚˜í•˜ë‚˜ê°€ ì‹¤ì œ ë²•ê´€ì˜ ì–¸ì–´ì²˜ëŸ¼ ì„¤ë“ë ¥ ìˆê³  ì‹ ì¤‘í•˜ê²Œ êµ¬ì„±ë˜ì–´ì•¼ í•¨\n",
    "- í˜•ì‹ì€ ë°˜ë“œì‹œ 'ì˜ˆìƒ íŒë‹¨ ìš”ì§€:' ì—†ì´ **íŒê²°ë¬¸ íŒë‹¨ ë¶€ë¶„ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œì‘**í•  ê²ƒ\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "##ì‚¬ê±´ ë¶„ì•¼##\n",
    "{case_type}\n",
    "\n",
    "##ì‚¬ì‹¤ê´€ê³„##\n",
    "{facts}\n",
    "\n",
    "##ìœ ì‚¬ íŒë¡€ ìš”ì•½##\n",
    "{precedents_summary}\n",
    "\n",
    "##ì ìš© ë²•ë ¹##\n",
    "{law_articles}\n",
    "\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format=LegalJudgmentResponse,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.parsed.judgment_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb390c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì–‘í˜• ì˜ˆì¸¡ ì—ì´ì „íŠ¸\n",
    "\n",
    "class SentencePredictionResponse(BaseModel):\n",
    "    predicted_sentence: str\n",
    "\n",
    "def predict_sentence(facts, law_articles, precedent_summary):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "**ì—­í• **\n",
    "ë„ˆëŠ” í˜•ì‚¬ ì‚¬ê±´ì— ëŒ€í•´ ì„ ê³ ë  ìˆ˜ ìˆëŠ” **ê°€ì¥ í˜„ì‹¤ì ì´ê³  ê°œì—°ì„± ë†’ì€ í˜•ëŸ‰**ì„ ì˜ˆì¸¡í•˜ëŠ” íŒì‚¬ ì—­í• ì´ì•¼.\n",
    "\n",
    "**ì…ë ¥ ì •ë³´**ëŠ” ì•„ë˜ì™€ ê°™ì•„:\n",
    "- ì‚¬ê±´ ë¶„ì•¼ (í˜•ì‚¬)\n",
    "- ê¸°ì´ˆ ì‚¬ì‹¤ (basic facts)\n",
    "- ë²•ì  ìŸì  (legal issue)\n",
    "- íŒë¡€ ê²€ìƒ‰ìš© ì§ˆì˜ (precedent queries)\n",
    "- ì‚¬ê±´ ë¶„ì•¼ ë¶„ë¥˜ ê²°ê³¼ (ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬)\n",
    "- ê´€ë ¨ íŒë¡€ ìš”ì•½ (precedent summary)\n",
    "- ì ìš© ë²•ë ¹ ëª©ë¡ (relevant laws)\n",
    "- ë²•ì›ì˜ ì˜ˆìƒ íŒë‹¨ ìš”ì§€ (legal judgment)\n",
    "\n",
    "ë„ˆëŠ” ì´ ëª¨ë“  ì •ë³´ë¥¼ í†µí•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì„œ, **ì„ ê³  í˜•ëŸ‰**ì„ êµ¬ì²´ì ìœ¼ë¡œ ì˜ˆì¸¡í•´ì•¼ í•´.\n",
    "\n",
    "**í˜•ì‹ ìš”ê±´**\n",
    "- ë°˜ë“œì‹œ í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ì•„ì•¼ í•¨:\n",
    "    - ì§•ì—­ â—‹ë…„ â—‹ì›”\n",
    "    - ì§•ì—­ â—‹ë…„ â—‹ì›”, ì§‘í–‰ìœ ì˜ˆ â—‹ë…„\n",
    "    - ë²Œê¸ˆ â—‹â—‹ë§Œì›\n",
    "- í˜•ì‚¬ì†Œì†¡ ê´€í–‰ì— ë¶€í•©í•˜ë„ë¡ ì‹¤ì œ ì„ ê³ ë¬¸ì²˜ëŸ¼ **ì‚¬ì‹¤ê´€ê³„ì˜ ì¤‘ëŒ€ì„±**, **ë°˜ì„± ì—¬ë¶€**, **í”¼í•´ íšŒë³µ**, **ì „ê³¼ ìœ ë¬´**, **ì–‘í˜•ê¸°ì¤€**, **ì°¸ì‘ ì‚¬ìœ ** ë“±ì„ ì¢…í•© íŒë‹¨í•´.\n",
    "- ë°˜ë“œì‹œ ì‹¤í˜•/ì§‘í–‰ìœ ì˜ˆ/ë²Œê¸ˆ ì—¬ë¶€ì™€ ê¸°ê°„ ë˜ëŠ” ì•¡ìˆ˜ë¥¼ ì •í™•íˆ ì œì‹œí•  ê²ƒ\n",
    "- ë³€í˜¸ì‚¬ë‚˜ ë²•ì¡°ì¸ì—ê²Œ ì œê³µí•  ìˆ˜ì¤€ì˜ ì‹¤ë¬´ì , ë…¼ë¦¬ì  íƒ€ë‹¹ì„±ì„ ê°–ì¶œ ê²ƒ\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"##ì‚¬ì‹¤ê´€ê³„##\\n{facts}\\n\\n##ì ìš© ë²•ë ¹##\\n{law_articles}\\n\\n##ìœ ì‚¬ íŒë¡€ ìš”ì•½##\\n{precedent_summary}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        response_format=SentencePredictionResponse,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.parsed.predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3a0f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (2.60.5)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (4.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (0.28.1)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (3.10)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langfuse) (1.17.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (4.13.2)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests<3,>=2->langfuse) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests<3,>=2->langfuse) (2.4.0)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langgraph in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph) (0.3.60)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.26 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph) (2.0.26)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph) (0.1.69)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph) (2.11.4)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph) (1.9.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langfuse\n",
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae623329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler(\n",
    "  secret_key=\"sk-lf-bc52adc2-5b9e-4516-b4d6-3c98ac4cee1e\",\n",
    "  public_key=\"pk-lf-e8844606-a8dd-4b87-9976-c2d151c27983\",\n",
    "  host=\"https://us.cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07e699ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langfuse CallbackHandler for Langgraph\n",
    "from __future__ import annotations        # â‡’ list[str] íƒ€ì… íŒíŠ¸ ì§€ì›\n",
    "from typing import TypedDict, Optional\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class LegalCaseState(TypedDict):\n",
    "    # â”€â”€â”€â”€â”€ ì½ê¸° ì „ìš© â”€â”€â”€â”€â”€\n",
    "    user_input: str                       # ìµœì´ˆ ì‚¬ìš©ì ì§ˆë¬¸\n",
    "\n",
    "    # â”€â”€â”€â”€â”€ ê° ë…¸ë“œì—ì„œ ì—…ë°ì´íŠ¸í•  í•„ë“œ â”€â”€â”€â”€â”€\n",
    "    legal_issue: Optional[str]            # âœ¦ ì´ìŠˆ ì¶”ì¶œ ë…¸ë“œ\n",
    "    precedent_queries: Optional[list[str]]# âœ¦ íŒë¡€ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë…¸ë“œ\n",
    "    precedent_summary: Optional[str]      # âœ¦ íŒë¡€ ìš”ì•½ ë…¸ë“œ\n",
    "    law_recommendation: Optional[str]     # âœ¦ ê´€ë ¨ ì¡°ë¬¸ ì¶”ì²œ ë…¸ë“œ\n",
    "    legal_judgment_prediction: Optional[str]  # âœ¦ íŒê²° ê²°ê³¼ ì˜ˆì¸¡ ë…¸ë“œ\n",
    "    sentence_prediction: Optional[str]    # âœ¦ í˜•ëŸ‰ ì˜ˆì¸¡ ë…¸ë“œ\n",
    "    basic_facts: Optional[list[str]]      # âœ¦ ì‚¬ì‹¤ê´€ê³„ ì¶”ì¶œ ë…¸ë“œ\n",
    "    case_categories: Optional[list[str]]  # âœ¦ ì‚¬ê±´ ë¶„ë¥˜ ë…¸ë“œ\n",
    "    final_answer: Optional[str]           # âœ¦ ìµœì¢… ë‹µë³€ ì¡°ë¦½ ë…¸ë“œ\n",
    "\n",
    "workflow = StateGraph(LegalCaseState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4d172e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "def classify_legal_domains_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    categories = classify_legal_domains(state[\"user_input\"])\n",
    "    return {\"case_categories\": categories}                 # âœ…\n",
    "\n",
    "def extract_basic_facts_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    facts = extract_basic_facts(state[\"user_input\"])\n",
    "    return {\"basic_facts\": facts}                          # âœ…\n",
    "\n",
    "def extract_legal_issue_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    issue = generate_legal_issue(state[\"user_input\"])\n",
    "    return {\"legal_issue\": issue}                          # âœ…\n",
    "\n",
    "def generate_precedent_queries_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    queries = generate_precedent_queries(\n",
    "        legal_issue=state[\"legal_issue\"],\n",
    "        basic_facts=state[\"basic_facts\"],\n",
    "        case_categories=state[\"case_categories\"]\n",
    "    )\n",
    "    return {\"precedent_queries\": queries}                  # âœ…\n",
    "\n",
    "def summarize_precedents_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    summary, matches = search_similar_precedents_from_supabase(\n",
    "        precedent_queries=state[\"precedent_queries\"],\n",
    "        legal_issue=state[\"legal_issue\"],\n",
    "        basic_facts=state[\"basic_facts\"],\n",
    "        legal_domains=state[\"case_categories\"]\n",
    "    )\n",
    "    return {\n",
    "        \"precedent_summary\": summary,\n",
    "        \"precedent_matches\": matches                       \n",
    "    }\n",
    "\n",
    "def recommend_law_node(state: LegalCaseState):\n",
    "    laws = recommend_relevant_laws(\n",
    "        legal_issue     = state[\"legal_issue\"],\n",
    "        facts           = state[\"basic_facts\"],\n",
    "        case_categories = state[\"case_categories\"],\n",
    "    )\n",
    "    return {\"law_recommendation\": laws}\n",
    "\n",
    "def simulate_judgment_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    judgment = simulate_judgment(\n",
    "        facts=state[\"basic_facts\"],\n",
    "        precedents_summary=state[\"precedent_summary\"],\n",
    "        law_articles=state[\"law_recommendation\"],\n",
    "        case_type=state[\"case_type\"]\n",
    "    )\n",
    "    return {\"legal_judgment_prediction\": judgment}\n",
    "\n",
    "def predict_sentence_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    sentence = predict_sentence(\n",
    "        facts=state[\"basic_facts\"],\n",
    "        law_articles=state[\"law_recommendation\"],\n",
    "        precedent_summary=state[\"precedent_summary\"]\n",
    "    )\n",
    "    return {\"sentence_prediction\": sentence}\n",
    "\n",
    "def generate_final_answer_node(state: LegalCaseState) -> LegalCaseState:\n",
    "    parts = [\n",
    "        f\"âœ… ì‚¬ê±´ ë¶„ì•¼: {', '.join(state['case_categories'])}\" if state.get(\"case_categories\") else \"\",\n",
    "        f\"ğŸ” ê¸°ì´ˆ ì‚¬ì‹¤: {'; '.join(state['basic_facts'])}\"    if state.get(\"basic_facts\") else \"\",\n",
    "        f\"âš–ï¸ ë²•ì  ìŸì : {state['legal_issue']}\"             if state.get(\"legal_issue\") else \"\",\n",
    "        f\"ğŸ“– ì ìš© ë²•ë ¹: {state['law_recommendation']}\"       if state.get(\"law_recommendation\") else \"\",\n",
    "        f\"ğŸ“š ìœ ì‚¬ íŒë¡€ ìš”ì•½: {state['precedent_summary']}\"  if state.get(\"precedent_summary\") else \"\",\n",
    "        f\"ğŸ§‘â€âš–ï¸ ì˜ˆìƒ íŒê²° ìš”ì§€: {state['legal_judgment_prediction']}\" if state.get(\"legal_judgment_prediction\") else \"\",\n",
    "    ]\n",
    "    if state.get(\"sentence_prediction\"):\n",
    "        parts.append(f\"ğŸ” ì˜ˆìƒ í˜•ëŸ‰: {state['sentence_prediction']}\")\n",
    "    final_output = \"\\n\".join([p for p in parts if p])\n",
    "    return {\"final_answer\": final_output}                   # âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc81fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì›Œí¬í”Œë¡œìš° langgraph ë²„ì „\n",
    "\n",
    "# from langgraph.graph import StateGraph\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# def create_workflow() -> StateGraph:\n",
    "#     workflow = StateGraph(LegalCaseState)\n",
    "\n",
    "#     # â”€â”€ 1ï¸âƒ£ ê³µí†µ ë…¸ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     workflow.add_node(\"ExtractLegalIssue\",  RunnableLambda(extract_legal_issue_node))\n",
    "#     workflow.add_node(\"ExtractBasicFacts\",  RunnableLambda(extract_basic_facts_node))\n",
    "#     workflow.add_node(\"ClassifyCaseType\",   RunnableLambda(classify_legal_domains_node))\n",
    "\n",
    "#     # ìµœì¢… ì‘ë‹µ ë…¸ë“œ\n",
    "#     workflow.add_node(\"GenerateFinalAnswer\", RunnableLambda(generate_final_answer_node))\n",
    "\n",
    "#     # â”€â”€ 2ï¸âƒ£ ì‚¬ê±´ ìœ í˜•ë³„ ë¸Œëœì¹˜ ì„¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     branch_labels = [\"ë¯¼ì‚¬\", \"í˜•ì‚¬\", \"í–‰ì •\"]\n",
    "#     for label in branch_labels:\n",
    "#         gq   = f\"GeneratePrecedentQuery_{label}\"\n",
    "#         sum_ = f\"SummarizePrecedents_{label}\"\n",
    "#         law  = f\"RecommendLaw_{label}\"\n",
    "#         sim  = f\"SimulateJudgment_{label}\"\n",
    "#         sen  = f\"PredictSentence_{label}\"   # í˜•ì‚¬ì—ë§Œ ì‚¬ìš©\n",
    "\n",
    "#         workflow.add_node(gq,  RunnableLambda(lambda s, l=label: generate_precedent_queries_node({**s, \"case_type\": l})))\n",
    "#         workflow.add_node(sum_, RunnableLambda(lambda s, l=label: summarize_precedents_node({**s, \"case_type\": l})))\n",
    "#         workflow.add_node(law, RunnableLambda(lambda s, l=label: recommend_law_node({**s, \"case_type\": l})))\n",
    "#         workflow.add_node(sim, RunnableLambda(lambda s, l=label: simulate_judgment_node({**s, \"case_type\": l})))\n",
    "#         if label == \"í˜•ì‚¬\":\n",
    "#             workflow.add_node(sen, RunnableLambda(lambda s, l=label: predict_sentence_node({**s, \"case_type\": l})))\n",
    "\n",
    "#         # ìˆœì°¨ ì—£ì§€ (ë¸Œëœì¹˜ ë‚´ë¶€)\n",
    "#         workflow.add_edge(gq,  sum_)\n",
    "#         workflow.add_edge(sum_, law)\n",
    "#         workflow.add_edge(law, sim)\n",
    "#         if label == \"í˜•ì‚¬\":\n",
    "#             workflow.add_edge(sim, sen)\n",
    "#             workflow.add_edge(sen, \"GenerateFinalAnswer\")\n",
    "#         else:\n",
    "#             workflow.add_edge(sim, \"GenerateFinalAnswer\")\n",
    "\n",
    "#     # â”€â”€ 3ï¸âƒ£ ì‚¬ê±´ ìœ í˜• ë¼ìš°íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     def case_router(state: LegalCaseState) -> str:\n",
    "#         \"\"\"case_categories ì¤‘ ì²« ë²ˆì§¸ ì¼ì¹˜ ë¼ë²¨ ë°˜í™˜, ì—†ìœ¼ë©´ 'ê¸°íƒ€'.\"\"\"\n",
    "#         cats = state.get(\"case_categories\") or []\n",
    "#         for l in (\"í˜•ì‚¬\", \"ë¯¼ì‚¬\", \"í–‰ì •\"):\n",
    "#             if l in cats:\n",
    "#                 return l\n",
    "#         return \"ê¸°íƒ€\"\n",
    "\n",
    "#     workflow.add_conditional_edges(\n",
    "#         \"ClassifyCaseType\",\n",
    "#         case_router,\n",
    "#         {\n",
    "#             \"ë¯¼ì‚¬\":  \"GeneratePrecedentQuery_ë¯¼ì‚¬\",\n",
    "#             \"í˜•ì‚¬\":  \"GeneratePrecedentQuery_í˜•ì‚¬\",\n",
    "#             \"í–‰ì •\":  \"GeneratePrecedentQuery_í–‰ì •\",\n",
    "#             \"ê¸°íƒ€\":  \"GenerateFinalAnswer\",        # fallback\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     # â”€â”€ 4ï¸âƒ£ ì§ë ¬ ê¸°ë³¸ íë¦„ (ëˆ„ë½ëë˜ ì—£ì§€ ë³µêµ¬) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     workflow.set_entry_point(\"ExtractLegalIssue\")\n",
    "#     workflow.add_edge(\"ExtractLegalIssue\", \"ExtractBasicFacts\")   # âœ… ì¶”ê°€\n",
    "#     workflow.add_edge(\"ExtractBasicFacts\", \"ClassifyCaseType\")    # âœ… ì¶”ê°€\n",
    "\n",
    "#     # â”€â”€ 5ï¸âƒ£ ì¢…ë£Œ ì§€ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#     workflow.set_finish_point(\"GenerateFinalAnswer\")\n",
    "\n",
    "#     return workflow.compile()\n",
    "\n",
    "# # â”€â”€ ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# graph = create_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9a8986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì›Œí¬í”Œë¡œ langfuse ë²„ì „\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langfuse.callback import CallbackHandler as LangfuseCallbackHandler\n",
    "import os\n",
    "\n",
    "# Langfuse í•¸ë“¤ëŸ¬ ì„¤ì •\n",
    "langfuse_handler = LangfuseCallbackHandler(\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\"),\n",
    ")\n",
    "\n",
    "def create_workflow() -> StateGraph:\n",
    "    workflow = StateGraph(LegalCaseState)\n",
    "\n",
    "    # â”€â”€ 1ï¸âƒ£ ê³µí†µ ë…¸ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    workflow.add_node(\"ExtractLegalIssue\",  RunnableLambda(extract_legal_issue_node))\n",
    "    workflow.add_node(\"ExtractBasicFacts\",  RunnableLambda(extract_basic_facts_node))\n",
    "    workflow.add_node(\"ClassifyCaseType\",   RunnableLambda(classify_legal_domains_node))\n",
    "    workflow.add_node(\"GenerateFinalAnswer\", RunnableLambda(generate_final_answer_node))\n",
    "\n",
    "    # â”€â”€ 2ï¸âƒ£ ë¸Œëœì¹˜ ë…¸ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    branch_labels = [\"ë¯¼ì‚¬\", \"í˜•ì‚¬\", \"í–‰ì •\"]\n",
    "    for label in branch_labels:\n",
    "        gq   = f\"GeneratePrecedentQuery_{label}\"\n",
    "        sum_ = f\"SummarizePrecedents_{label}\"\n",
    "        law  = f\"RecommendLaw_{label}\"\n",
    "        sim  = f\"SimulateJudgment_{label}\"\n",
    "        sen  = f\"PredictSentence_{label}\"\n",
    "\n",
    "        workflow.add_node(gq,  RunnableLambda(lambda s, l=label: generate_precedent_queries_node({**s, \"case_type\": l})))\n",
    "        workflow.add_node(sum_, RunnableLambda(lambda s, l=label: summarize_precedents_node({**s, \"case_type\": l})))\n",
    "        workflow.add_node(law, RunnableLambda(lambda s, l=label: recommend_law_node({**s, \"case_type\": l})))\n",
    "        workflow.add_node(sim, RunnableLambda(lambda s, l=label: simulate_judgment_node({**s, \"case_type\": l})))\n",
    "        if label == \"í˜•ì‚¬\":\n",
    "            workflow.add_node(sen, RunnableLambda(lambda s, l=label: predict_sentence_node({**s, \"case_type\": l})))\n",
    "\n",
    "        workflow.add_edge(gq,  sum_)\n",
    "        workflow.add_edge(sum_, law)\n",
    "        workflow.add_edge(law, sim)\n",
    "        if label == \"í˜•ì‚¬\":\n",
    "            workflow.add_edge(sim, sen)\n",
    "            workflow.add_edge(sen, \"GenerateFinalAnswer\")\n",
    "        else:\n",
    "            workflow.add_edge(sim, \"GenerateFinalAnswer\")\n",
    "\n",
    "    # â”€â”€ 3ï¸âƒ£ ì‚¬ê±´ ë¶„ë¥˜ ì¡°ê±´ë¶€ íë¦„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def case_router(state: LegalCaseState) -> str:\n",
    "        cats = state.get(\"case_categories\") or []\n",
    "        for l in (\"í˜•ì‚¬\", \"ë¯¼ì‚¬\", \"í–‰ì •\"):\n",
    "            if l in cats:\n",
    "                return l\n",
    "        return \"ê¸°íƒ€\"\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"ClassifyCaseType\",\n",
    "        case_router,\n",
    "        {\n",
    "            \"ë¯¼ì‚¬\":  \"GeneratePrecedentQuery_ë¯¼ì‚¬\",\n",
    "            \"í˜•ì‚¬\":  \"GeneratePrecedentQuery_í˜•ì‚¬\",\n",
    "            \"í–‰ì •\":  \"GeneratePrecedentQuery_í–‰ì •\",\n",
    "            \"ê¸°íƒ€\":  \"GenerateFinalAnswer\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # â”€â”€ 4ï¸âƒ£ ê¸°ë³¸ ì§ë ¬ ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    workflow.set_entry_point(\"ExtractLegalIssue\")\n",
    "    workflow.add_edge(\"ExtractLegalIssue\", \"ExtractBasicFacts\")\n",
    "    workflow.add_edge(\"ExtractBasicFacts\", \"ClassifyCaseType\")\n",
    "    workflow.set_finish_point(\"GenerateFinalAnswer\")\n",
    "\n",
    "    # âœ… Langfuse íŠ¸ë˜í‚¹ ì ìš©\n",
    "    return workflow.compile().with_config({\n",
    "        \"callbacks\": [langfuse_handler]\n",
    "    })\n",
    "\n",
    "# ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "graph = create_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f71164c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ê±´ ë¶„ì•¼: ë¯¼ì‚¬\n",
      "ğŸ” ê¸°ì´ˆ ì‚¬ì‹¤: 1. ì›ê³ ëŠ” 2022ë…„ 3ì›” 1ì¼ë¶€í„° í”¼ê³  ì†Œìœ ì˜ ì„œìš¸ì‹œ ë§ˆí¬êµ¬ ì†Œì¬ ë‹¤ì„¸ëŒ€ì£¼íƒ 2ì¸µì„ ì „ì„¸ë³´ì¦ê¸ˆ 1ì–µ 5ì²œë§Œ ì›ì— ì„ì°¨í•˜ì˜€ë‹¤.; 2. ê³„ì•½ê¸°ê°„ì€ 2ë…„ìœ¼ë¡œ 2024ë…„ 2ì›” 29ì¼ê¹Œì§€ë¡œ ì •í•´ì¡Œë‹¤.; 3. ì›ê³ ì™€ í”¼ê³ ëŠ” í‘œì¤€ì„ëŒ€ì°¨ê³„ì•½ì„œë¥¼ ì‘ì„±í•˜ì˜€ìœ¼ë©° ë³´ì¦ê¸ˆ ë°˜í™˜ì— ê´€í•œ íŠ¹ì•½ì‚¬í•­ì€ ëª…ì‹œë˜ì§€ ì•Šì•˜ë‹¤.; 4. ì›ê³ ëŠ” ê³„ì•½ ì¢…ë£Œì¼ì— ë§ì¶”ì–´ ì´ì‚¬ë¥¼ ì¤€ë¹„í•˜ì˜€ìœ¼ë©° ìƒˆë¡œìš´ ê±°ì²˜ë„ ë§ˆë ¨í•˜ì˜€ë‹¤.; 5. í”¼ê³ ëŠ” ì´ì‚¬ í•˜ë£¨ ì „ì¸ 2024ë…„ 2ì›” 28ì¼, ë³´ì¦ê¸ˆ ë§ˆë ¨ì´ ë˜ì§€ ì•Šì•„ ë°˜í™˜ì„ ë¯¸ë£° ìˆ˜ë°–ì— ì—†ë‹¤ê³  í†µë³´í•˜ì˜€ë‹¤.; 6. ì›ê³ ëŠ” ì´ì‚¬ í›„ ë³´ì¦ê¸ˆ ë°˜í™˜ ìš”ì²­ì„ ë‚´ìš©ì¦ëª…ìœ¼ë¡œ í”¼ê³ ì—ê²Œ ë°œì†¡í•˜ì˜€ë‹¤.; 7. í”¼ê³ ëŠ” ê³„ì†ì ìœ¼ë¡œ ìê¸ˆ ì‚¬ì •ì„ ì´ìœ ë¡œ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ë¯¸ë£¨ê³  ìˆë‹¤.; 8. í•´ë‹¹ ì£¼íƒì—ëŠ” ìƒˆë¡œìš´ ì„¸ì…ìê°€ ë“¤ì–´ì˜¤ì§€ ì•Šì€ ìƒíƒœì´ë‹¤.; 9. í”¼ê³ ëŠ” ë³´ì¦ê¸ˆ ë°˜í™˜ ê³„íš ë° ì¼ì •ì„ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì§€ ì•Šê³  ìˆë‹¤.; 10. ì›ê³ ëŠ” ì€í–‰ ëŒ€ì¶œë¡œ ìƒˆ ì§‘ ì „ì„¸ìê¸ˆì„ ì¶©ë‹¹í•˜ì˜€ë‹¤.; 11. í”¼ê³ ëŠ” ì—°ë½ì„ íšŒí”¼í•˜ë©° ì „í™”ë‚˜ ë©”ì‹œì§€ì— ì œëŒ€ë¡œ ì‘ë‹µí•˜ì§€ ì•Šê³  ìˆë‹¤.\n",
      "âš–ï¸ ë²•ì  ìŸì : 1. ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ í›„ ì„ëŒ€ì¸ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ ë¶ˆì´í–‰ì— ëŒ€í•œ ë²•ì  ì±…ì„ \n",
      "\n",
      "2. ì„ì°¨ì¸ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ì²­êµ¬ê¶Œ í–‰ì‚¬ ì ˆì°¨: ë‚´ìš©ì¦ëª… ë°œì†¡, ì†Œì†¡ ì œê¸° í•„ìš”ì„± \n",
      "\n",
      "3. ì„ëŒ€ì¸ì˜ ì—°ë½ íšŒí”¼ ë° ë¶€ë‹¹í•œ ì§€ì—°ì— ë”°ë¥¸ ì±„ë¬´ë¶ˆì´í–‰ ë° ì†í•´ë°°ìƒ ì²­êµ¬ ê°€ëŠ¥ì„± \n",
      "\n",
      "4. ë³´ì¦ê¸ˆ ë°˜í™˜ ì§€ì—°ì— ë”°ë¥¸ ì§€ì—°ì†í•´ê¸ˆ ì²­êµ¬ ë²”ìœ„ ë° ì‚°ì • ë°©ë²• \n",
      "\n",
      "5. ì„ì°¨ì¸ì´ ì€í–‰ ëŒ€ì¶œì„ í†µí•´ ì´ì‚¬ë¹„ìš©ì„ ì¶©ë‹¹í•¨ì— ë”°ë¼ ë°œìƒí•œ ì¶”ê°€ ì†í•´ ë° ì´ì— ëŒ€í•œ ë°°ìƒ ì²­êµ¬ ê°€ëŠ¥ì„± \n",
      "\n",
      "6. ê³„ì•½ í•´ì§€ í›„ ì„ì°¨ì¸ì´ ìš”êµ¬í•  ìˆ˜ ìˆëŠ” ê°•ì œì§‘í–‰ì„ ìœ„í•œ ë³´ì „ì²˜ë¶„, ê°€ì••ë¥˜ ë“± ì‹ ì²­ í•„ìš”ì„± \n",
      "\n",
      "7. ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ì— ê·¼ê±°í•œ ì„ì°¨ì¸ ë³´í˜¸ ì¡°í•­ ë° ì´ì— ë”°ë¥¸ íš¨ë ¥ í™•ì¸ \n",
      "\n",
      "8. ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ì§€ ëª»í•˜ëŠ” ìƒí™©ì—ì„œì˜ ì†Œì†¡ ì¤€ë¹„: ê³„ì•½ì„œ, ë‚´ìš©ì¦ëª…, ëŒ€ì¶œ ì¦ë¹™ ë“± ì¦ê±° ìˆ˜ì§‘ \n",
      "\n",
      "9. ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ë°˜í™˜ì²­êµ¬ ì†Œì†¡ì—ì„œì˜ ì ˆì°¨ì  ì§„í–‰: ì†Œì†¡ ì œê¸°, ë²•ì› íŒê²°, ê°•ì œì§‘í–‰ ëª…ë ¹ ì‹ ì²­ ë“± ë‹¨ê³„ \n",
      "\n",
      "10. ì„ëŒ€ì°¨ ê³„ì•½ì‹œ íŠ¹ì•½ì‚¬í•­ ë¶€ì¬ë¡œ ì¸í•œ ë¯¼ë²• ìƒ ì„ëŒ€ê³„ì•½ì˜ ê¸°ë³¸ ì˜ë¬´ ì ìš© ì—¬ë¶€ \n",
      "\n",
      "11. ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹ ì‹ ì²­ì„ í†µí•œ ì„ì°¨ì¸ì˜ ê¶Œë¦¬ ê°•í™” ë° ìƒˆë¡œìš´ ì„ëŒ€ì°¨ ê³„ì•½ ì²´ê²° ì§€ì› ë°©ì•ˆ \n",
      "\n",
      "12. í–¥í›„ ì†Œì†¡ ê³¼ì •ì—ì„œ ìƒëŒ€ë°©ì˜ ìì‚° ìƒíƒœ íŒŒì•… ë° ì§‘í–‰ ê°€ëŠ¥ì„± ì¡°ì‚¬ í•„ìš”ì„± \n",
      "\n",
      "13. ì†Œë©¸ì‹œíš¨ ë° ë³´ì¦ê¸ˆ ë°˜í™˜ì²­êµ¬ì— ëŒ€í•œ ì…ì¦ì±…ì„ ë¬¸ì œ ë° ì ì ˆí•œ ëŒ€ì‘ ë°©ì•ˆ\n",
      "ğŸ“– ì ìš© ë²•ë ¹: ['ë¯¼ë²• ì œ618ì¡° (ì„ëŒ€ì°¨ì˜ ì •ì˜)', 'ë¯¼ë²• ì œ623ì¡° (ì„ëŒ€ì¸ì˜ ì˜ë¬´)', 'ë¯¼ë²• ì œ750ì¡° (ë¶ˆë²•í–‰ìœ„)', 'ë¯¼ë²• ì œ390ì¡° (ì±„ë¬´ë¶ˆì´í–‰ê³¼ ì†í•´ë°°ìƒ)', 'ë¯¼ë²• ì œ548ì¡° (í•´ì œì™€ ì›ìƒíšŒë³µ)', 'ë¯¼ë²• ì œ391ì¡° (ì±„ë¬´ë¶ˆì´í–‰ì— ëŒ€í•œ ì†í•´ë°°ìƒì•¡ì˜ ì‚°ì •)', 'ë¯¼ë²• ì œ662ì¡° (ì„ì°¨ê¶Œì˜ ì–‘ë„ì™€ ì „ëŒ€)', 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ3ì¡° (ëŒ€í•­ë ¥ ë“±)', 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ4ì¡° (ê³„ì•½ê°±ì‹ ê³¼ ë³´ì¦ê¸ˆ ë°˜í™˜)', 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡° (ë³´ì¦ê¸ˆì˜ íšŒìˆ˜ ë³´ì¥)', 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ8ì¡° (ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹ ì œë„)', 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ10ì¡° (ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ë°˜í™˜ ì˜ë¬´)', 'ë¯¼ì‚¬ì†Œì†¡ë²• ì œ704ì¡° (ê°€ì••ë¥˜ì˜ ì¼ë°˜ìš”ê±´)', 'ë¯¼ì‚¬ì†Œì†¡ë²• ì œ721ì¡° (ë³´ì „ì²˜ë¶„ì˜ ì‹ ì²­)', 'ì±„ê¶ŒìíšŒìƒ ë° íŒŒì‚°ì— ê´€í•œ ë²•ë¥  ì œ351ì¡° (íšŒìƒì ˆì°¨ ì¤‘ ì¼ë°˜ êµí™˜ì˜ ì œí•œ)']\n",
      "ğŸ“š ìœ ì‚¬ íŒë¡€ ìš”ì•½: ### ìœ ì‚¬ íŒë¡€ ìš”ì•½\n",
      "\n",
      "#### ì‚¬ê±´ë²ˆí˜¸: 2018ê°€ë‹¨521112 / ì‚¬ê±´ëª…: ë³´ì¦ê¸ˆë°˜í™˜\n",
      "\n",
      "**ì‚¬ì‹¤ê´€ê³„:**\n",
      "- ì›ê³ ëŠ” í”¼ê³  ì†Œìœ ì˜ ì•„íŒŒíŠ¸ë¥¼ ì„ì°¨í•˜ì—¬ ê±°ì£¼í•˜ì˜€ê³ , ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ ì‹œì ì— ë³´ì¦ê¸ˆì„ ë°˜í™˜ë°›ì§€ ëª»í•˜ì˜€ë‹¤.\n",
      "- í”¼ê³ ëŠ” ìê¸ˆ ì‚¬ì •ì„ ì´ìœ ë¡œ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ì§€ì—°í•˜ì˜€ìœ¼ë©°, ì´ì— ëŒ€í•´ ì›ê³ ëŠ” ë‚´ìš©ì¦ëª…ì„ í†µí•´ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ìš”ì²­í•˜ì˜€ë‹¤.\n",
      "- í”¼ê³ ëŠ” ë³´ì¦ê¸ˆ ë°˜í™˜ ê³„íšì„ ëª…í™•íˆ ì œì‹œí•˜ì§€ ì•Šì•˜ê³ , ì—°ë½ì„ íšŒí”¼í•˜ì˜€ë‹¤.\n",
      "\n",
      "**ìŸì :**\n",
      "1. **ì„ëŒ€ì¸ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ì˜ë¬´ ë¶ˆì´í–‰:** ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ í›„ ì„ëŒ€ì¸ì€ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•  ì˜ë¬´ê°€ ìˆìœ¼ë©°, ì´ë¥¼ ì´í–‰í•˜ì§€ ì•Šì„ ê²½ìš° ì±„ë¬´ë¶ˆì´í–‰ì— í•´ë‹¹í•œë‹¤.\n",
      "2. **ë³´ì¦ê¸ˆ ë°˜í™˜ì²­êµ¬ê¶Œ í–‰ì‚¬:** ì„ì°¨ì¸ì€ ë‚´ìš©ì¦ëª…ì„ í†µí•´ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ê³µì‹ì ìœ¼ë¡œ ìš”ì²­í•  ìˆ˜ ìˆìœ¼ë©°, ë°˜í™˜ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì„ ê²½ìš° ì†Œì†¡ì„ ì œê¸°í•  ìˆ˜ ìˆë‹¤.\n",
      "3. **ì±„ë¬´ë¶ˆì´í–‰ ë° ì†í•´ë°°ìƒ:** ì„ëŒ€ì¸ì˜ ì—°ë½ íšŒí”¼ ë° ë¶€ë‹¹í•œ ì§€ì—°ì€ ì±„ë¬´ë¶ˆì´í–‰ìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìœ¼ë©°, ì´ì— ë”°ë¥¸ ì†í•´ë°°ìƒì„ ì²­êµ¬í•  ìˆ˜ ìˆë‹¤.\n",
      "4. **ì§€ì—°ì†í•´ê¸ˆ:** ë³´ì¦ê¸ˆ ë°˜í™˜ ì§€ì—°ì— ë”°ë¥¸ ì§€ì—°ì†í•´ê¸ˆì„ ì²­êµ¬í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ë²•ì •ì´ììœ¨ì— ë”°ë¼ ì‚°ì •ëœë‹¤.\n",
      "5. **ì„ì°¨ì¸ì˜ ì¶”ê°€ ì†í•´:** ì„ì°¨ì¸ì´ ëŒ€ì¶œì„ í†µí•´ ìƒˆë¡œìš´ ê±°ì²˜ë¥¼ ë§ˆë ¨í•œ ê²½ìš°, ì´ì— ë”°ë¥¸ ì¶”ê°€ ì†í•´ë¥¼ ë°°ìƒë°›ì„ ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€ê°€ ìŸì ì´ ëœë‹¤.\n",
      "\n",
      "**íŒê²°:**\n",
      "- ë²•ì›ì€ í”¼ê³ ê°€ ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ í›„ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ì§€ ì•Šì€ ê²ƒì€ ëª…ë°±í•œ ì±„ë¬´ë¶ˆì´í–‰ì´ë¼ê³  íŒë‹¨í•˜ì˜€ë‹¤.\n",
      "- ì›ê³ ëŠ” ë³´ì¦ê¸ˆ ë°˜í™˜ ì²­êµ¬ì™€ í•¨ê»˜ ì§€ì—°ì†í•´ê¸ˆì„ ì²­êµ¬í•  ê¶Œë¦¬ê°€ ìˆìœ¼ë©°, í”¼ê³ ëŠ” ì´ë¥¼ ì§€ê¸‰í•  ì˜ë¬´ê°€ ìˆë‹¤ê³  íŒì‹œí•˜ì˜€ë‹¤.\n",
      "- ì„ì°¨ì¸ì´ ëŒ€ì¶œë¡œ ì¸í•´ ë°œìƒí•œ ì¶”ê°€ ì†í•´ì— ëŒ€í•´ì„œëŠ” êµ¬ì²´ì ì¸ ì…ì¦ì´ í•„ìš”í•˜ë©°, ì´ì— ëŒ€í•œ ë°°ìƒì€ ë³„ë„ì˜ íŒë‹¨ì´ í•„ìš”í•˜ë‹¤ê³  ë³´ì•˜ë‹¤.\n",
      "\n",
      "**ê´€ë ¨ ë²•ë¦¬:**\n",
      "- ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ë° ë¯¼ë²•ìƒ ì„ëŒ€ì°¨ ê³„ì•½ì˜ ê¸°ë³¸ ì˜ë¬´ì— ë”°ë¼ ì„ëŒ€ì¸ì€ ê³„ì•½ ì¢…ë£Œ ì‹œ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•  ì˜ë¬´ê°€ ìˆë‹¤.\n",
      "- ì„ì°¨ì¸ì€ ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹ì„ ì‹ ì²­í•˜ì—¬ ìì‹ ì˜ ê¶Œë¦¬ë¥¼ ê°•í™”í•  ìˆ˜ ìˆìœ¼ë©°, ë³´ì¦ê¸ˆ ë°˜í™˜ ì²­êµ¬ ì†Œì†¡ì„ í†µí•´ ë²•ì  êµ¬ì œë¥¼ ë°›ì„ ìˆ˜ ìˆë‹¤.\n",
      "\n",
      "ì´ íŒë¡€ëŠ” ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ì§€ ì•Šì„ ê²½ìš° ì„ì°¨ì¸ì´ ì·¨í•  ìˆ˜ ìˆëŠ” ë²•ì  ì ˆì°¨ì™€ ê·¸ì— ë”°ë¥¸ ë²•ì›ì˜ íŒë‹¨ì„ ë³´ì—¬ì¤€ë‹¤. ì„ì°¨ì¸ì€ ë‚´ìš©ì¦ëª… ë°œì†¡, ì†Œì†¡ ì œê¸°, ì§€ì—°ì†í•´ê¸ˆ ì²­êµ¬ ë“±ì˜ ì ˆì°¨ë¥¼ í†µí•´ ê¶Œë¦¬ë¥¼ ë³´í˜¸ë°›ì„ ìˆ˜ ìˆë‹¤.\n",
      "ğŸ§‘â€âš–ï¸ ì˜ˆìƒ íŒê²° ìš”ì§€: ë³¸ ì‚¬ê±´ì€ ì›ê³ ê°€ í”¼ê³ ë¡œë¶€í„° ì„ì°¨í•œ ì£¼íƒì— ëŒ€í•œ ì„ëŒ€ì°¨ ê³„ì•½ì´ ì¢…ë£Œëœ í›„, í”¼ê³ ê°€ ì•½ì •ëœ ì „ì„¸ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒìœ¼ë¡œ ì¸í•´ ë°œìƒí•œ ë¯¼ì‚¬ ì‚¬ê±´ì´ë‹¤. ì´ì— ëŒ€í•œ ë²•ì›ì˜ íŒë‹¨ì€ ì•„ë˜ì™€ ê°™ë‹¤.\n",
      "\n",
      "ë¨¼ì € ë³¸ê±´ì— ì ìš©ë  ë²•ë¦¬ë¡œëŠ” ë¯¼ë²• ì œ618ì¡° ë° ì œ623ì¡°ì— ì˜ê±°í•´ ì„ëŒ€ì°¨ ê³„ì•½ì˜ ë³¸ì§ˆê³¼ ì„ëŒ€ì¸ì˜ ì˜ë¬´ê°€ ìˆìœ¼ë©°, ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ8ì¡° ë° ì œ10ì¡°ì— ë”°ë¼ëŠ” ì„ì°¨ì¸ì˜ ëŒ€í•­ë ¥ ë° ì„ëŒ€ì¸ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ ì˜ë¬´ê°€ ëª…ì‹œë˜ì–´ ìˆë‹¤. ì´ëŸ¬í•œ ë²•ê·œì •ì— ë”°ë¼, ì„ëŒ€ì¸ì€ ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ í›„ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•  ì˜ë¬´ê°€ ìˆìŒì´ ë¶„ëª…í•˜ë‹¤.\n",
      "\n",
      "ì´ì— ë¹„ì¶”ì–´, í”¼ê³ ê°€ ì„ì°¨ê¸°ê°„ ì¢…ë£Œ í›„ ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ë¯¸ë£¨ê³  ìˆëŠ” í–‰ìœ„ëŠ” ë¯¼ë²• ì œ390ì¡°ì— ë”°ë¥¸ ì±„ë¬´ë¶ˆì´í–‰ì— í•´ë‹¹ëœë‹¤. ìœ ì‚¬ íŒë¡€(2018ê°€ë‹¨521112)ì—ì„œë„ ìœ ì‚¬í•œ ìƒí™©ì´ ìˆì—ˆê³ , ë²•ì›ì€ ì„ëŒ€ì¸ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ ì˜ë¬´ë¥¼ ì†Œí™€íˆ í•˜ëŠ” ê²ƒì€ ëª…ë°±í•œ ì±„ë¬´ë¶ˆì´í–‰ì´ë¼ê³  íŒì‹œí•œ ë°” ìˆë‹¤. ë”°ë¼ì„œ ë³¸ ì‚¬ê±´ì—ì„œë„ í”¼ê³ ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ ì§€ì—°ì€ ì±„ë¬´ë¶ˆì´í–‰ìœ¼ë¡œ ì¸ì •ëœë‹¤.\n",
      "\n",
      "í•œí¸, ì›ê³ ëŠ” í”¼ê³ ì˜ ë³´ì¦ê¸ˆ ë°˜í™˜ ê±°ë¶€ì— ëŒ€ì‘í•˜ì—¬ ë‚´ìš©ì¦ëª…ì„ ë°œì†¡í•˜ì˜€ê³ , ì´ëŠ” ë¯¼ì‚¬ í”„ë¡œì„¸ìŠ¤ì—ì„œ ê¶Œë¦¬ í–‰ì‚¬ì— ëŒ€í•œ ê³µì‹ì  ë°©ë²•ì„ì´ ì¸ì •ëœë‹¤(ë¯¼ë²• ì œ390ì¡°, ì±„ê¶Œìì˜ ì²­êµ¬ê¶Œ í–‰ì‚¬). í”¼ê³ ê°€ ì´ë¥¼ ë‹µë³€í•˜ì§€ ì•Šê³  ì—°ë½ì„ íšŒí”¼í•˜ëŠ” ê²ƒì€ ê·¸ ì±…ì„ì˜ ë¬´ê±°ì›€ì„ ê°€ì¤‘ì‹œí‚¤ëŠ” ì‚¬ì •ìœ¼ë¡œ ê°„ì£¼ëœë‹¤.\n",
      "\n",
      "ì¶”ê°€ì ìœ¼ë¡œ í”¼ê³ ì˜ í–‰ìœ„ë¡œ ì¸í•´ ì›ê³ ê°€ ì…ê²Œ ë˜ëŠ” ì†í•´, íŠ¹íˆ ì§€ì—°ì†í•´ê¸ˆì˜ ë¶€ê³¼ ì—¬ë¶€ì— ëŒ€í•´ ë³¸ ë²•ì›ì€ ìœ ì‚¬ íŒë¡€ì˜ ê²°ë¡ ì„ ì°¸ê³ í•˜ì—¬, ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ ë°˜í™˜ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ì†í•´ì— ëŒ€í•œ ë°°ìƒì„ ì¸ì •í•œë‹¤. ë²•ì •ì´ìœ¨ì— ë”°ë¼ ê³„ì‚°ëœ ê¸ˆì•¡ì´ ì›ê³ ì—ê²Œ ì§ì ‘ ì§€ê¸‰ë˜ì–´ì•¼ í•  ê²ƒìœ¼ë¡œ íŒë‹¨í•œë‹¤.\n",
      "\n",
      "ì›ê³ ê°€ ì€í–‰ ëŒ€ì¶œì„ í†µí•´ ìƒˆë¡œìš´ ê±°ì²˜ë¥¼ ë§ˆë ¨í•´ì•¼ í–ˆë‹¤ëŠ” ì ì€ í”¼ê³ ë¡œ ì¸í•œ ì¶”ê°€ì ì¸ ì†í•´ ë°œìƒì˜ ê·¼ê±°ê°€ ë  ìˆ˜ ìˆë‹¤. ë¯¼ë²• ì œ750ì¡° ë° ì œ391ì¡°ì— ì˜ê±°í•œ ë¶ˆë²•í–‰ìœ„ ì±…ì„ ë° ì†í•´ë°°ìƒ ì²­êµ¬ëŠ” ë³¸ ì‚¬ì•ˆì—ì„œ êµ¬ì²´ì ì¸ ì…ì¦ì´ ìš”êµ¬ëœë‹¤. ê·¸ëŸ¬ë‚˜, ì´ì™€ ê´€ë ¨ëœ ë°°ìƒ ì—¬ë¶€ëŠ” ì¶”ê°€ ì‹¬ë¦¬ë¥¼ í•„ìš”ë¡œ í•œë‹¤.\n",
      "\n",
      "ê²°ë¡ ì ìœ¼ë¡œ ë³¸ ë²•ì›ì€ í”¼ê³ ê°€ ì„ëŒ€ì°¨ ê³„ì•½ ì¢…ë£Œ í›„ ì •ë‹¹í•œ ê¸°ê°„ ë‚´ì— ì›ê³ ì—ê²Œ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ì§€ ì•Šì€ í–‰ìœ„ê°€ ì±„ë¬´ë¶ˆì´í–‰ì— í•´ë‹¹í•˜ë©°, ì›ê³ ëŠ” ê·¸ë¡œ ì¸í•œ ì§€ì—°ì†í•´ê¸ˆì„ ì²­êµ¬í•  ìˆ˜ ìˆìŒì„ ì¸ì •í•œë‹¤. í”¼ê³ ëŠ” ì›ê³ ì—ê²Œ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ10ì¡°ì— ë”°ë¥¸ ë³´ì¦ê¸ˆì„ ë°˜í™˜í•˜ê³ , ì´ì— ë”°ë¥¸ ì§€ì—°ì†í•´ê¸ˆì„ ì§€ê¸‰í•  ë²•ì  ì˜ë¬´ê°€ ìˆë‹¤. í•˜ì§€ë§Œ ëŒ€ì¶œë¡œ ì¸í•´ ë°œìƒí•œ ì¶”ê°€ ì†í•´ì— ëŒ€í•œ ë°°ìƒì€ ì›ê³  ì¸¡ì´ êµ¬ì²´ì ì¸ ì†í•´ë¥¼ ì…ì¦í•  í•„ìš”ê°€ ìˆìœ¼ë©°, ì´ì— ëŒ€í•œ ë³„ë„ì˜ ì‹¬ë¦¬ê°€ ìš”êµ¬ëœë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ ì •ì˜ (LegalCaseState ê¸°ì¤€)\n",
    "state = {\n",
    "    \"user_input\": \"\"\"\n",
    "ì €ëŠ” 2022ë…„ 3ì›” 1ì¼ë¶€í„° ì„œìš¸ì‹œ ë§ˆí¬êµ¬ì— ìˆëŠ” ë‹¤ì„¸ëŒ€ì£¼íƒì˜ 2ì¸µì„ ì „ì„¸ë¡œ ì„ì°¨í•˜ì—¬ ê±°ì£¼í•´ ì™”ìŠµë‹ˆë‹¤.  \n",
    "ê³„ì•½ ë‹¹ì‹œ ë³´ì¦ê¸ˆì€ 1ì–µ 5ì²œë§Œ ì›ì´ì—ˆê³ , ê³„ì•½ê¸°ê°„ì€ 2ë…„ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆì—ˆìœ¼ë©°, 2024ë…„ 2ì›” 29ì¼ì— ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
    "ì§‘ì£¼ì¸ê³¼ëŠ” í‘œì¤€ì„ëŒ€ì°¨ê³„ì•½ì„œë¥¼ ì‘ì„±í•˜ì˜€ê³ , ë³´ì¦ê¸ˆ ë°˜í™˜ê³¼ ê´€ë ¨í•˜ì—¬ íŠ¹ì•½ì‚¬í•­ì€ ë”°ë¡œ ëª…ì‹œí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  \n",
    "ê³„ì•½ ê°±ì‹ ì€ í•˜ì§€ ì•Šê¸°ë¡œ í•˜ê³ , ì €ëŠ” ê³„ì•½ ì¢…ë£Œì¼ì— ë§ì¶° ì´ì‚¬ë¥¼ ì¤€ë¹„í•˜ê³  ìƒˆë¡œìš´ ê±°ì²˜ë„ ë§ˆë ¨í•˜ì˜€ìŠµë‹ˆë‹¤.  \n",
    "\n",
    "í•˜ì§€ë§Œ ì´ì‚¬ í•˜ë£¨ ì „ì¸ 2024ë…„ 2ì›” 28ì¼, ì§‘ì£¼ì¸ì´ ê°‘ìê¸° ë³´ì¦ê¸ˆì´ ë‹¹ì¥ ë§ˆë ¨ë˜ì§€ ì•Šì•˜ë‹¤ë©° ë°˜í™˜ì„ ë¯¸ë£° ìˆ˜ë°–ì— ì—†ë‹¤ê³  í†µë³´í•´ ì™”ìŠµë‹ˆë‹¤.  \n",
    "ì´ì— ë”°ë¼ ì €ëŠ” ì¼ë‹¨ ìƒˆ ì§‘ìœ¼ë¡œ ì´ì‚¬ë¥¼ ì™„ë£Œí•œ í›„, ë³´ì¦ê¸ˆ ë°˜í™˜ì„ ìš”ì²­í•˜ëŠ” ë‚´ìš©ì¦ëª…ì„ ë³´ëƒˆì§€ë§Œ,  \n",
    "ì§‘ì£¼ì¸ì€ ê³„ì†í•´ì„œ â€œìê¸ˆ ì‚¬ì •ì´ ì–´ë µë‹¤â€ëŠ” ì´ìœ ë¡œ ë°˜í™˜ì„ ë¯¸ë£¨ê³  ìˆìŠµë‹ˆë‹¤.  \n",
    "\n",
    "í˜„ì¬ í•´ë‹¹ ì£¼íƒì—ëŠ” ìƒˆë¡œìš´ ì„¸ì…ìë„ ë“¤ì–´ì˜¤ì§€ ì•Šì€ ìƒíƒœì´ë©°,  \n",
    "ì§‘ì£¼ì¸ì€ ì „ì„¸ë³´ì¦ê¸ˆì„ ë°˜í™˜í•  ê³„íšë„, ì¼ì •ë„ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.  \n",
    "ì €ëŠ” í•´ë‹¹ ë³´ì¦ê¸ˆìœ¼ë¡œ ìƒˆ ì§‘ ì „ì„¸ìê¸ˆì„ ì¶©ë‹¹í•´ì•¼ í•˜ëŠ” ìƒí™©ì´ì—ˆê¸°ì—  \n",
    "í˜„ì¬ ì€í–‰ ëŒ€ì¶œì„ ë°›ì•„ ì´ì‚¬ë¹„ìš©ì„ ì¶©ë‹¹í•œ ìƒíƒœì´ë©°, ì´ë¡œ ì¸í•´ ê²½ì œì  ì†í•´ì™€ ì •ì‹ ì  ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ìƒë‹¹í•©ë‹ˆë‹¤.  \n",
    "\n",
    "ë˜í•œ ì§‘ì£¼ì¸ì€ ì—°ë½ì„ íšŒí”¼í•˜ê³  ìˆìœ¼ë©°, ì „í™”ë‚˜ ë©”ì‹œì§€ì—ë„ ì œëŒ€ë¡œ ì‘ë‹µí•˜ì§€ ì•Šê³  ìˆì–´ ìë ¥ìœ¼ë¡œ ë³´ì¦ê¸ˆì„ ëŒë ¤ë°›ê¸° ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤.  \n",
    "ì´ëŸ¬í•œ ìƒí™©ì—ì„œ ì œê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ë²•ì  ì¡°ì¹˜ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆìœ¼ë©°,  \n",
    "ì‹¤ì œë¡œ ì†Œì†¡ì„ ì§„í–‰í•˜ê²Œ ëœë‹¤ë©´ ì–´ë–¤ ì ˆì°¨ì™€ ì¦ê±°ê°€ í•„ìš”í•œì§€,  \n",
    "ë³´ì¦ê¸ˆì„ ëŒë ¤ë°›ê¸°ê¹Œì§€ ì–¼ë§ˆë‚˜ ê±¸ë¦´ ìˆ˜ ìˆëŠ”ì§€ ë“± êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# LangGraph ì‹¤í–‰\n",
    "result = graph.invoke(state)\n",
    "\n",
    "# ìµœì¢… ë‹µë³€ ì¶œë ¥\n",
    "print(result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcffa9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_input', 'legal_issue', 'precedent_queries', 'precedent_summary', 'law_recommendation', 'legal_judgment_prediction', 'basic_facts', 'case_categories', 'final_answer'])\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke(state)\n",
    "print(result.keys())          # ì–´ë–¤ í‚¤ê°€ ë‚´ë ¤ì™”ëŠ”ì§€ ë¨¼ì € í™•ì¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
