# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Supabase ê¸°ë°˜ íŒë¡€ ê²€ìƒ‰ ì—ì´ì „íŠ¸ (vector-based re-ranking)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
Prerequisite
------------
1. Supabase Postgresì— pgvector í™•ì¥ ì„¤ì¹˜
   CREATE EXTENSION IF NOT EXISTS vector;
2. precedents_full í…Œì´ë¸”ì— ë‹¤ìŒ ë²¡í„° ì»¬ëŸ¼ ì¡´ì¬
   - bsisfacts_vector    vector(1536)
   - courtdcss_vector    vector(1536)
   - relatelaword_vector vector(1536)
3. Python íŒ¨í‚¤ì§€: openai, supabase-py, numpy, python-dotenv
"""
from __future__ import annotations

import os, json, numpy as np
from typing import List, Tuple
from functools import lru_cache
from dotenv import load_dotenv
from supabase import create_client, Client
from openai import OpenAI
from postgrest.exceptions import APIError

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
SUPABASE_URL         = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")
OPENAI_API_KEY       = os.getenv("OPENAI_API_KEY")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
oai              = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ util: any â†’ str â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _to_text(x) -> str:
    """
    embed() ì— ì•ˆì „í•˜ê²Œ ë„˜ê¸¸ ìˆ˜ ìˆë„ë¡ íƒ€ì…ì„ ë¬¸ìì—´ë¡œ ì •ê·œí™”
    â€¢ list/tuple  â†’ ì¤„ë°”ê¿ˆ join
    â€¢ dict       â†’ pretty JSON
    â€¢ None       â†’ ""
    â€¢ ê¸°íƒ€       â†’ str(x)
    """
    if x is None:
        return ""
    if isinstance(x, (list, tuple)):
        return "\n".join(map(str, x))
    if isinstance(x, dict):
        return json.dumps(x, ensure_ascii=False, indent=2)
    return str(x)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ util: ì„ë² ë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@lru_cache(maxsize=1024)
def embed(text: str, model: str = "text-embedding-3-small") -> List[float]:
    """OpenAI ì„ë² ë”© í˜¸ì¶œ ê²°ê³¼ë¥¼ LRU ìºì‹œ"""
    resp = oai.embeddings.create(model=model, input=text)
    return resp.data[0].embedding    # 1536-D (3-small ê¸°ì¤€)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_similar_precedents_from_supabase(
    *,                               # keyword-only
    basic_facts:  str | list | dict | None = None,
    legal_issue:  str | list | dict | None = None,
    related_laws: str | list | dict | None = None,
    legal_domains:     str | None = None,
    case_type:         str | None = None,
    # search params
    top_k:   int   = 5,
    w_facts: float = 0.4,
    w_issue: float = 0.4,
    w_law:   float = 0.2,
) -> Tuple[str, List[dict]]:
    """pgvector + GPT-4o ìš”ì•½ ê¸°ë°˜ ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰"""

    # 0ï¸âƒ£ alias ë§¤í•‘ -------------------------------------------------
    if case_type is None and legal_domains is not None:
        case_type = legal_domains
    case_type = case_type or "civil"          # ê¸°ë³¸ê°’

    # ğŸ‘‰ ë¦¬ìŠ¤íŠ¸Â·íŠœí”Œì´ë©´ ì²« ë²ˆì§¸ ì›ì†Œ(ë˜ëŠ” join)ë§Œ ì‚¬ìš©
    if isinstance(case_type, (list, tuple)):
        case_type = case_type[0] if case_type else "civil"
    case_type = str(case_type)                # ë°©ì–´ì  ìºìŠ¤íŒ…

    # ğŸ†• ì˜ë¬¸ â†’ êµ­ë¬¸ ë§¤í•‘
    CASE_TYPE_MAP = {
        "civil"   : "ë¯¼ì‚¬",
        "criminal": "í˜•ì‚¬",
        "admin"   : "í–‰ì •",
    }
    case_type = CASE_TYPE_MAP.get(case_type, case_type)   # ë³€í™˜

    # 1ï¸âƒ£ ë¬¸ìì—´ ì •ê·œí™” ---------------------------------------------
    basic_facts  = _to_text(basic_facts)
    legal_issue  = _to_text(legal_issue)
    related_laws = _to_text(related_laws)

    # 2ï¸âƒ£ ì„ë² ë”© ------------------------------------------------------
    fact_vec  = embed(basic_facts)
    issue_vec = embed(legal_issue)
    law_vec   = embed(related_laws)

    # 3ï¸âƒ£ Supabase RPC í˜¸ì¶œ -----------------------------------------
    payload = {
        "case_type": case_type,
        "fact_vec":  fact_vec,
        "issue_vec": issue_vec,
        "law_vec":   law_vec,
        "w_f":       w_facts,
        "w_i":       w_issue,
        "w_l":       w_law,
        "k":         top_k,
    }
    try:
        res = supabase.rpc("top_k_precedents", payload).execute()
    except APIError as e:
        # Handle Postgres statement timeout (code 57014) and other DB errors gracefully
        if getattr(e, "message", "") and "statement timeout" in str(e.message):
            return "â° Supabase ì¿¼ë¦¬ê°€ ì‹œê°„ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì…ë ¥ì„ ìš”ì•½í•˜ê±°ë‚˜ top_k ê°’ì„ ì¤„ì—¬ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", []
        else:
            raise
    matches: List[dict] = res.data or []
    if not matches:
        return "ğŸ” ìœ ì‚¬í•œ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

    # 4ï¸âƒ£ GPT-4o íŒë¡€ ìš”ì•½ ------------------------------------------
    cases_list = "\n".join(
        f"- ì‚¬ê±´ë²ˆí˜¸: {c['caseno']} / ì‚¬ê±´ëª…: {c.get('casenm','')}"
        for c in matches
    )
    summary_prompt = f"""
ë‹¹ì‹ ì€ íŒë¡€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì‚¬ê±´ì˜ ì‚¬ì‹¤ê´€ê³„Â·ìŸì ì— ìœ ì‚¬í•œ íŒë¡€ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.

## ê¸°ì´ˆ ì‚¬ì‹¤
{basic_facts}

## ë²•ì  ìŸì 
{legal_issue}

## ê´€ë ¨ ì¡°ë¬¸
{related_laws}

## ìœ ì‚¬ íŒë¡€ ëª©ë¡
{cases_list}
"""
    chat = oai.chat.completions.create(
        model="gpt-4o",
        temperature=0.3,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë²•ë¥  íŒë¡€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user",    "content": summary_prompt.strip()},
        ],
    )
    summary_text = chat.choices[0].message.content.strip()
    return summary_text, matches